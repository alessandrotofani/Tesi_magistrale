{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Federated.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnGGnl2oPGnC3CvEJUoED3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/6_Federated_sistemato.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XuZ_oMl43ft"
      },
      "source": [
        "Overview: https://www.tensorflow.org/federated\r\n",
        "\r\n",
        "Image classification tutorial: https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOKJPHxH4j9j"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgkJJpzD4gVs"
      },
      "source": [
        "!pip install --quiet tensorflow==2.3.0\r\n",
        "!pip install --quiet tensorflow_federated==0.17.0\r\n",
        "!pip install --quiet --upgrade nest_asyncio\r\n",
        "# !pip install -q tfds-nightly"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Oguz1e4p29"
      },
      "source": [
        "import nest_asyncio\r\n",
        "nest_asyncio.apply()\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u_qzOek4tlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01f1c26-75a0-465d-b226-04d0b4b8a323"
      },
      "source": [
        "import collections\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_federated as tff\r\n",
        "import pandas as pd \r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5VvCBjWmrJC"
      },
      "source": [
        "import sys \n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\n",
        "import mf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU2jrVgkla8Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67D33H0kldvF"
      },
      "source": [
        "data = mf.feature_engineering(data)\n",
        "# data = mf.feature_scaling(data)\n",
        "data = pd.get_dummies(data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yGwMV9Us42h"
      },
      "source": [
        "data = data[200000:300000]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfjplhmow-8N"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuQfRXzrqoW2"
      },
      "source": [
        "def to_tensor(data, n_clients = 5):\n",
        "  shuffled = data.sample(frac=1)\n",
        "  result = np.array_split(shuffled, n_clients)  \n",
        "\n",
        "  res = []\n",
        "\n",
        "  new_res = []\n",
        "  label = []\n",
        "\n",
        "  for dataset in result:\n",
        "    res.append(mf.feature_scaling(dataset))\n",
        "  \n",
        "  for subset in res:\n",
        "    label.append(subset['isFraud'])\n",
        "    new_res.append(subset.drop(columns = ['isFraud']).to_numpy())\n",
        "\n",
        "  dataset = {}\n",
        "  for i in range(n_clients):\n",
        "    dataset[i] = tf.data.Dataset.from_tensor_slices((new_res[i], label[i]))\n",
        "  return dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LozyQwZOrCub"
      },
      "source": [
        "dataset = to_tensor(train_data)\n",
        "test_set = to_tensor(test_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHxlJrXRs9qP"
      },
      "source": [
        "NUM_CLIENTS = 5\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 1000\n",
        "SHUFFLE_BUFFER = 10\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(e1, e2):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x = tf.cast(e1, tf.float32),\n",
        "        y = tf.cast(e2, tf.int32))\n",
        "      #  x=tf.reshape(element, [-1, 1103]),\n",
        "      #  y=tf.reshape(target, [-1, 1]))\n",
        "        # element)\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "preprocessed_example_dataset = preprocess(dataset[0])\n",
        "\n",
        "# sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "#                                      next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "# sample_batch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6coH5NXYrQ8A",
        "outputId": "1198a44c-e342-4fd9-ee90-16e0bf1b5cd0"
      },
      "source": [
        "def make_federated_data(dataset):\n",
        "  federated = []\n",
        "  for i in dataset:\n",
        "    federated.append(preprocess(dataset[i]))\n",
        "  return federated\n",
        "\n",
        "federated_train_data = make_federated_data(dataset)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of client datasets: 5\n",
            "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 1103)), (y, (None,))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4A7FqBv8G7f",
        "outputId": "c4f5d599-7b7f-4ba2-a636-f91f11ad4d08"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input\n",
        "\n",
        "def create_keras_model():\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(1103,))) \n",
        "  # model.add(Dense(1024, activation='relu')) \n",
        "  # model.add(Dropout(0.2)) \n",
        "  # model.add(Dense(512, activation='relu')) \n",
        "  # model.add(Dropout(0.2)) \n",
        "  model.add(Dense(256, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(128, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(24, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(4, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  soglia = 0.2\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
        "               tf.keras.metrics.Recall(thresholds=soglia),\n",
        "               tf.keras.metrics.Precision(thresholds=soglia)])\n",
        "  \n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,  \n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.4), #0.4\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.8)) #0.8\n",
        "\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.08213514), ('precision', 0.08011316), ('loss', 0.17514537)]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLvHl-fA7wW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b5c09e-a509-4f59-ac94-6139ac94eca0"
      },
      "source": [
        "NUM_ROUNDS = 141\n",
        "for round_num in range(2, NUM_ROUNDS):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.052175254), ('precision', 0.15558009), ('loss', 0.15786746)]))])\n",
            "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.024004936), ('precision', 0.18418561), ('loss', 0.15323715)]))])\n",
            "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.15073921)]))])\n",
            "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.0), ('precision', 0.0), ('loss', 0.1489567)]))])\n",
            "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14792353)]))])\n",
            "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14731051)]))])\n",
            "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14658612)]))])\n",
            "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14616212)]))])\n",
            "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14560843)]))])\n",
            "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14513804)]))])\n",
            "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14472534)]))])\n",
            "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.0), ('precision', 0.0), ('loss', 0.1444112)]))])\n",
            "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.1440888)]))])\n",
            "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14350078)]))])\n",
            "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14311008)]))])\n",
            "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.0), ('precision', 0.0), ('loss', 0.14289483)]))])\n",
            "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.013884604), ('precision', 0.3529412), ('loss', 0.142294)]))])\n",
            "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.025732799), ('precision', 0.34180328), ('loss', 0.14198294)]))])\n",
            "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.06066029), ('precision', 0.31241062), ('loss', 0.14192069)]))])\n",
            "round 21, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.2181117), ('precision', 0.30106473), ('loss', 0.14135763)]))])\n",
            "round 22, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.28336933), ('precision', 0.29927006), ('loss', 0.14087038)]))])\n",
            "round 23, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.31345263), ('precision', 0.30199167), ('loss', 0.14089014)]))])\n",
            "round 24, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.326751), ('precision', 0.30263194), ('loss', 0.14027958)]))])\n",
            "round 25, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.33286023), ('precision', 0.3018889), ('loss', 0.14011353)]))])\n",
            "round 26, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.3412527), ('precision', 0.3067876), ('loss', 0.13967253)]))])\n",
            "round 27, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.3507868), ('precision', 0.30539662), ('loss', 0.13940471)]))])\n",
            "round 28, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.35075593), ('precision', 0.3091567), ('loss', 0.13935086)]))])\n",
            "round 29, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.36251158), ('precision', 0.31432086), ('loss', 0.13839334)]))])\n",
            "round 30, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.36497995), ('precision', 0.3067687), ('loss', 0.13861598)]))])\n",
            "round 31, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.37170628), ('precision', 0.3136423), ('loss', 0.13802725)]))])\n",
            "round 32, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.3720765), ('precision', 0.3169251), ('loss', 0.13780294)]))])\n",
            "round 33, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.38040727), ('precision', 0.3166641), ('loss', 0.13765195)]))])\n",
            "round 34, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.3845418), ('precision', 0.31817716), ('loss', 0.13713111)]))])\n",
            "round 35, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.39086702), ('precision', 0.3192621), ('loss', 0.13714124)]))])\n",
            "round 36, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.39179265), ('precision', 0.3242346), ('loss', 0.13671383)]))])\n",
            "round 37, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594876), ('recall', 0.39355138), ('precision', 0.32550722), ('loss', 0.136452)]))])\n",
            "round 38, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.39814872), ('precision', 0.32539022), ('loss', 0.13597214)]))])\n",
            "round 39, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.40459734), ('precision', 0.32353014), ('loss', 0.13592654)]))])\n",
            "round 40, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.40561554), ('precision', 0.33065876), ('loss', 0.13540898)]))])\n",
            "round 41, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.40762112), ('precision', 0.32987913), ('loss', 0.1356571)]))])\n",
            "round 42, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.41283554), ('precision', 0.33316734), ('loss', 0.13493194)]))])\n",
            "round 43, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.41798827), ('precision', 0.3315792), ('loss', 0.13471052)]))])\n",
            "round 44, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.4220611), ('precision', 0.33634955), ('loss', 0.1345773)]))])\n",
            "round 45, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.42027152), ('precision', 0.33314583), ('loss', 0.13435999)]))])\n",
            "round 46, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.42452946), ('precision', 0.33614287), ('loss', 0.13390347)]))])\n",
            "round 47, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.42955878), ('precision', 0.34355798), ('loss', 0.1334042)]))])\n",
            "round 48, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.42881826), ('precision', 0.33871952), ('loss', 0.13365977)]))])\n",
            "round 49, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.43434125), ('precision', 0.34482166), ('loss', 0.13293697)]))])\n",
            "round 50, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.43486577), ('precision', 0.34991807), ('loss', 0.13266893)]))])\n",
            "round 51, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.435884), ('precision', 0.3481014), ('loss', 0.13244279)]))])\n",
            "round 52, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.44279543), ('precision', 0.35687464), ('loss', 0.13172176)]))])\n",
            "round 53, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.44156125), ('precision', 0.3486661), ('loss', 0.13212693)]))])\n",
            "round 54, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.43992594), ('precision', 0.35056058), ('loss', 0.13228692)]))])\n",
            "round 55, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.44640544), ('precision', 0.34827402), ('loss', 0.1319697)]))])\n",
            "round 56, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.45158902), ('precision', 0.35883984), ('loss', 0.13108166)]))])\n",
            "round 57, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.4503548), ('precision', 0.35491794), ('loss', 0.1314409)]))])\n",
            "round 58, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.45029312), ('precision', 0.35949355), ('loss', 0.13082702)]))])\n",
            "round 59, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.45436594), ('precision', 0.36050725), ('loss', 0.13040596)]))])\n",
            "round 60, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.45853132), ('precision', 0.35645583), ('loss', 0.1304791)]))])\n",
            "round 61, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.45921013), ('precision', 0.36746332), ('loss', 0.12973085)]))])\n",
            "round 62, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.46420857), ('precision', 0.36577362), ('loss', 0.12962237)]))])\n",
            "round 63, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.46751), ('precision', 0.36283526), ('loss', 0.1292529)]))])\n",
            "round 64, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.464116), ('precision', 0.3620478), ('loss', 0.12967747)]))])\n",
            "round 65, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.47047207), ('precision', 0.37020493), ('loss', 0.12883033)]))])\n",
            "round 66, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.46788028), ('precision', 0.37046808), ('loss', 0.12876266)]))])\n",
            "round 67, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.47056463), ('precision', 0.36663702), ('loss', 0.12901825)]))])\n",
            "round 68, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.47272447), ('precision', 0.3734461), ('loss', 0.12833431)]))])\n",
            "round 69, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.48031473), ('precision', 0.3747833), ('loss', 0.1277686)]))])\n",
            "round 70, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.48102438), ('precision', 0.37377128), ('loss', 0.12748866)]))])\n",
            "round 71, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.48111695), ('precision', 0.37033606), ('loss', 0.12775452)]))])\n",
            "round 72, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.47479174), ('precision', 0.37538117), ('loss', 0.12758154)]))])\n",
            "round 73, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.48333848), ('precision', 0.37141976), ('loss', 0.1275572)]))])\n",
            "round 74, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.48691761), ('precision', 0.37885916), ('loss', 0.12651074)]))])\n",
            "round 75, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.4829991), ('precision', 0.38224307), ('loss', 0.12636375)]))])\n",
            "round 76, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.48963282), ('precision', 0.38187024), ('loss', 0.12610747)]))])\n",
            "round 77, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.49092874), ('precision', 0.3754011), ('loss', 0.12615654)]))])\n",
            "round 78, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.49049675), ('precision', 0.38254404), ('loss', 0.12597832)]))])\n",
            "round 79, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.4947547), ('precision', 0.38167667), ('loss', 0.12567738)]))])\n",
            "round 80, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.49311942), ('precision', 0.38175997), ('loss', 0.1257351)]))])\n",
            "round 81, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.49993828), ('precision', 0.38663262), ('loss', 0.124937825)]))])\n",
            "round 82, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.498303), ('precision', 0.3852852), ('loss', 0.12522848)]))])\n",
            "round 83, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.49731565), ('precision', 0.38606912), ('loss', 0.124733075)]))])\n",
            "round 84, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.49879667), ('precision', 0.38800883), ('loss', 0.12482399)]))])\n",
            "round 85, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.50209814), ('precision', 0.3863302), ('loss', 0.124638095)]))])\n",
            "round 86, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.50691146), ('precision', 0.38999668), ('loss', 0.12409956)]))])\n",
            "round 87, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5084542), ('precision', 0.39074764), ('loss', 0.12374335)]))])\n",
            "round 88, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5076828), ('precision', 0.38845998), ('loss', 0.12357439)]))])\n",
            "round 89, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.50836164), ('precision', 0.3883559), ('loss', 0.123878255)]))])\n",
            "round 90, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.51175565), ('precision', 0.3939948), ('loss', 0.12301589)]))])\n",
            "round 91, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.51444), ('precision', 0.39572307), ('loss', 0.12268875)]))])\n",
            "round 92, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.5128047), ('precision', 0.39707568), ('loss', 0.122521326)]))])\n",
            "round 93, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.51323664), ('precision', 0.39563316), ('loss', 0.122402236)]))])\n",
            "round 94, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.5151805), ('precision', 0.39716935), ('loss', 0.12192933)]))])\n",
            "round 95, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.51724774), ('precision', 0.39676228), ('loss', 0.121936426)]))])\n",
            "round 96, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.521012), ('precision', 0.3967482), ('loss', 0.122158065)]))])\n",
            "round 97, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.52024066), ('precision', 0.39924702), ('loss', 0.121519245)]))])\n",
            "round 98, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.52428263), ('precision', 0.39673126), ('loss', 0.12156471)]))])\n",
            "round 99, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.52597964), ('precision', 0.4032693), ('loss', 0.12064044)]))])\n",
            "round 100, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.5274298), ('precision', 0.39840582), ('loss', 0.12082996)]))])\n",
            "round 101, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.52767664), ('precision', 0.4042835), ('loss', 0.12048246)]))])\n",
            "round 102, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.5281395), ('precision', 0.399398), ('loss', 0.12087256)]))])\n",
            "round 103, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.53446466), ('precision', 0.4048142), ('loss', 0.11991478)]))])\n",
            "round 104, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5298365), ('precision', 0.40401855), ('loss', 0.12011874)]))])\n",
            "round 105, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.5315952), ('precision', 0.40388674), ('loss', 0.11967809)]))])\n",
            "round 106, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5327985), ('precision', 0.4018337), ('loss', 0.11998183)]))])\n",
            "round 107, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.530577), ('precision', 0.4061024), ('loss', 0.12010433)]))])\n",
            "round 108, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.53721076), ('precision', 0.40516138), ('loss', 0.11914213)]))])\n",
            "round 109, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594876), ('recall', 0.5351435), ('precision', 0.40477967), ('loss', 0.11947905)]))])\n",
            "round 110, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.54224), ('precision', 0.40643862), ('loss', 0.11831994)]))])\n",
            "round 111, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.5400185), ('precision', 0.40449283), ('loss', 0.11881159)]))])\n",
            "round 112, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.5416847), ('precision', 0.40216246), ('loss', 0.118771106)]))])\n",
            "round 113, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.54149956), ('precision', 0.4075803), ('loss', 0.118327014)]))])\n",
            "round 114, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.54637456), ('precision', 0.41357404), ('loss', 0.11751878)]))])\n",
            "round 115, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5496452), ('precision', 0.4103852), ('loss', 0.11738978)]))])\n",
            "round 116, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.5368713), ('precision', 0.40330058), ('loss', 0.11872419)]))])\n",
            "round 117, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.54912066), ('precision', 0.40827236), ('loss', 0.11749469)]))])\n",
            "round 118, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.55115706), ('precision', 0.41143817), ('loss', 0.117100924)]))])\n",
            "round 119, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.5547362), ('precision', 0.41123995), ('loss', 0.11677659)]))])\n",
            "round 120, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.55063254), ('precision', 0.4161459), ('loss', 0.11644992)]))])\n",
            "round 121, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.5533786), ('precision', 0.4071787), ('loss', 0.117273144)]))])\n",
            "round 122, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.55236036), ('precision', 0.41091678), ('loss', 0.1162732)]))])\n",
            "round 123, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.55782163), ('precision', 0.4114755), ('loss', 0.11608796)]))])\n",
            "round 124, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.5556001), ('precision', 0.4114099), ('loss', 0.116392404)]))])\n",
            "round 125, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.555631), ('precision', 0.4136632), ('loss', 0.11620271)]))])\n",
            "round 126, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948756), ('recall', 0.559025), ('precision', 0.41667816), ('loss', 0.11524163)]))])\n",
            "round 127, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.55489045), ('precision', 0.41401538), ('loss', 0.11612834)]))])\n",
            "round 128, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.55961126), ('precision', 0.41517684), ('loss', 0.115506425)]))])\n",
            "round 129, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.5564641), ('precision', 0.41318244), ('loss', 0.11575659)]))])\n",
            "round 130, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5623573), ('precision', 0.41943204), ('loss', 0.11493336)]))])\n",
            "round 131, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5607837), ('precision', 0.41574216), ('loss', 0.11508053)]))])\n",
            "round 132, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5635606), ('precision', 0.413254), ('loss', 0.115047246)]))])\n",
            "round 133, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.56784946), ('precision', 0.421202), ('loss', 0.1144938)]))])\n",
            "round 134, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.569639), ('precision', 0.4220754), ('loss', 0.11394578)]))])\n",
            "round 135, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.56821966), ('precision', 0.4176816), ('loss', 0.113958225)]))])\n",
            "round 136, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594874), ('recall', 0.5707189), ('precision', 0.42085505), ('loss', 0.11437511)]))])\n",
            "round 137, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5678186), ('precision', 0.42136234), ('loss', 0.11356803)]))])\n",
            "round 138, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.57081145), ('precision', 0.41969147), ('loss', 0.1138307)]))])\n",
            "round 139, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9594873), ('recall', 0.57645786), ('precision', 0.42298898), ('loss', 0.11314632)]))])\n",
            "round 140, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95948744), ('recall', 0.5716754), ('precision', 0.42074665), ('loss', 0.1134)]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-43k3etjd8P"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
        "train_metrics = evaluation(state.model, federated_train_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECb3PNHFjk_k"
      },
      "source": [
        "federated_test_data = make_federated_data(test_set)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GoNPIG8Qj0G8",
        "outputId": "d8908a88-cd80-4a0e-e807-b53a582c70e5"
      },
      "source": [
        "test_metrics = evaluation(state.model, federated_test_data)\n",
        "str(test_metrics)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"OrderedDict([('binary_accuracy', 0.9583001), ('recall', 0.5), ('precision', 0.48041475), ('loss', 0.12911011)])\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezubvjWqluK-"
      },
      "source": [
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "state = iterative_process.initialize()\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics['train'].items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM1FgnQao2-h"
      },
      "source": [
        "!ls {logdir}\n",
        "%tensorboard --logdir {logdir} --port=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbnAIOJWo528"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}