{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Federated.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNfS1qQ3P/Dm5YdjrFzRrwR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/6_Federated_sistemato_high.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XuZ_oMl43ft"
      },
      "source": [
        "Overview: https://www.tensorflow.org/federated\r\n",
        "\r\n",
        "Image classification tutorial: https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOKJPHxH4j9j"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgkJJpzD4gVs",
        "outputId": "8c44f78c-8e04-4613-b42b-20ab4f02d987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --quiet tensorflow==2.3.0\r\n",
        "!pip install --quiet tensorflow_federated==0.17.0\r\n",
        "!pip install --quiet --upgrade nest_asyncio\r\n",
        "# !pip install -q tfds-nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 320.4MB 58kB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 49.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.1MB 174kB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 522kB 16.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 53.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 60.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 56.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 48.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 58.0MB/s \n",
            "\u001b[?25h  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Oguz1e4p29"
      },
      "source": [
        "import nest_asyncio\r\n",
        "nest_asyncio.apply()\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u_qzOek4tlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72b5db5-99f8-4fbe-9d51-088d2066249b"
      },
      "source": [
        "import collections\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_federated as tff\r\n",
        "import pandas as pd \r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5VvCBjWmrJC"
      },
      "source": [
        "import sys \n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\n",
        "import mf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU2jrVgkla8Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67D33H0kldvF"
      },
      "source": [
        "data = mf.feature_engineering(data)\n",
        "# data = mf.feature_scaling(data)\n",
        "data = pd.get_dummies(data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yGwMV9Us42h"
      },
      "source": [
        "data = data[200000:300000]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfjplhmow-8N"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuQfRXzrqoW2"
      },
      "source": [
        "def to_tensor(data, n_clients = 5):\n",
        "  shuffled = data.sample(frac=1)\n",
        "  result = np.array_split(shuffled, n_clients)  \n",
        "\n",
        "  res = []\n",
        "\n",
        "  new_res = []\n",
        "  label = []\n",
        "\n",
        "  for dataset in result:\n",
        "    res.append(mf.feature_scaling(dataset))\n",
        "  \n",
        "  for subset in res:\n",
        "    label.append(subset['isFraud'])\n",
        "    new_res.append(subset.drop(columns = ['isFraud']).to_numpy())\n",
        "\n",
        "  dataset = {}\n",
        "  for i in range(n_clients):\n",
        "    dataset[i] = tf.data.Dataset.from_tensor_slices((new_res[i], label[i]))\n",
        "  return dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LozyQwZOrCub"
      },
      "source": [
        "dataset = to_tensor(train_data)\n",
        "test_set = to_tensor(test_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHxlJrXRs9qP"
      },
      "source": [
        "NUM_CLIENTS = 5\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 1000\n",
        "SHUFFLE_BUFFER = 10\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(e1, e2):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x = tf.cast(e1, tf.float32),\n",
        "        y = tf.cast(e2, tf.int32))\n",
        "      #  x=tf.reshape(element, [-1, 1103]),\n",
        "      #  y=tf.reshape(target, [-1, 1]))\n",
        "        # element)\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "preprocessed_example_dataset = preprocess(dataset[0])\n",
        "\n",
        "# sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "#                                      next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "# sample_batch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6coH5NXYrQ8A",
        "outputId": "1a0c4e01-4c31-4ede-bd02-8d4a8702920b"
      },
      "source": [
        "def make_federated_data(dataset):\n",
        "  federated = []\n",
        "  for i in dataset:\n",
        "    federated.append(preprocess(dataset[i]))\n",
        "  return federated\n",
        "\n",
        "federated_train_data = make_federated_data(dataset)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of client datasets: 5\n",
            "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 1103)), (y, (None,))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4A7FqBv8G7f",
        "outputId": "61e21c36-53e8-41e7-9711-3b2a4e278945"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input\n",
        "\n",
        "def create_keras_model():\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(1103,))) \n",
        "  # model.add(Dense(1024, activation='relu')) \n",
        "  # model.add(Dropout(0.2)) \n",
        "  # model.add(Dense(512, activation='relu')) \n",
        "  # model.add(Dropout(0.2)) \n",
        "  model.add(Dense(256, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(128, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(24, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(4, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  soglia = 0.1\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
        "               tf.keras.metrics.Recall(thresholds=soglia),\n",
        "               tf.keras.metrics.Precision(thresholds=soglia)])\n",
        "  \n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,  \n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.4), #0.4\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1)) #0.8\n",
        "\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9579599), ('recall', 0.44466463), ('precision', 0.08639277), ('loss', 0.17918219)]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLvHl-fA7wW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae860d74-f5ef-40a2-ec0e-0c82fb84f81c"
      },
      "source": [
        "NUM_ROUNDS = 141\n",
        "for round_num in range(2, NUM_ROUNDS):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.959), ('recall', 0.4814329), ('precision', 0.12639473), ('loss', 0.15802497)]))])\n",
            "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95899993), ('recall', 0.4839329), ('precision', 0.14137734), ('loss', 0.15457867)]))])\n",
            "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95899993), ('recall', 0.47560975), ('precision', 0.153569), ('loss', 0.15203857)]))])\n",
            "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95899874), ('recall', 0.45472562), ('precision', 0.16722164), ('loss', 0.14969952)]))])\n",
            "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95899373), ('recall', 0.43792683), ('precision', 0.17788455), ('loss', 0.14801718)]))])\n",
            "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95900244), ('recall', 0.42216465), ('precision', 0.18430966), ('loss', 0.14713927)]))])\n",
            "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9590673), ('recall', 0.37042683), ('precision', 0.19718905), ('loss', 0.1460268)]))])\n",
            "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9591174), ('recall', 0.36698171), ('precision', 0.20013301), ('loss', 0.14512785)]))])\n",
            "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.959235), ('recall', 0.3760061), ('precision', 0.20276202), ('loss', 0.1443317)]))])\n",
            "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.95949477), ('recall', 0.37445122), ('precision', 0.20594253), ('loss', 0.14348723)]))])\n",
            "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9596712), ('recall', 0.37810975), ('precision', 0.20880194), ('loss', 0.14284186)]))])\n",
            "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9599274), ('recall', 0.37765244), ('precision', 0.20921512), ('loss', 0.14248636)]))])\n",
            "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.960085), ('recall', 0.38310975), ('precision', 0.21127495), ('loss', 0.14191195)]))])\n",
            "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9603473), ('recall', 0.38655487), ('precision', 0.2179571), ('loss', 0.14087339)]))])\n",
            "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96053374), ('recall', 0.39054877), ('precision', 0.21930425), ('loss', 0.1403061)]))])\n",
            "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9605887), ('recall', 0.38759145), ('precision', 0.22002423), ('loss', 0.14030579)]))])\n",
            "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9608276), ('recall', 0.393811), ('precision', 0.22279525), ('loss', 0.13937473)]))])\n",
            "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96088487), ('recall', 0.39716464), ('precision', 0.22466154), ('loss', 0.1389965)]))])\n",
            "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9608999), ('recall', 0.39981708), ('precision', 0.22718453), ('loss', 0.1384725)]))])\n",
            "round 21, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9613988), ('recall', 0.39612806), ('precision', 0.23198472), ('loss', 0.13768417)]))])\n",
            "round 22, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9616349), ('recall', 0.39621952), ('precision', 0.23648009), ('loss', 0.13680796)]))])\n",
            "round 23, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9615812), ('recall', 0.4020122), ('precision', 0.23768409), ('loss', 0.13640542)]))])\n",
            "round 24, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96198237), ('recall', 0.40259147), ('precision', 0.24421142), ('loss', 0.13575399)]))])\n",
            "round 25, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96195376), ('recall', 0.40405488), ('precision', 0.24403852), ('loss', 0.13545084)]))])\n",
            "round 26, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.962025), ('recall', 0.40829268), ('precision', 0.24563913), ('loss', 0.13513292)]))])\n",
            "round 27, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9622038), ('recall', 0.40207317), ('precision', 0.25046054), ('loss', 0.13489255)]))])\n",
            "round 28, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9623637), ('recall', 0.40990853), ('precision', 0.24712802), ('loss', 0.13442837)]))])\n",
            "round 29, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96271497), ('recall', 0.41036585), ('precision', 0.2562638), ('loss', 0.13332291)]))])\n",
            "round 30, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96251005), ('recall', 0.4077744), ('precision', 0.25432593), ('loss', 0.13369253)]))])\n",
            "round 31, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9626312), ('recall', 0.4164939), ('precision', 0.25630873), ('loss', 0.13305213)]))])\n",
            "round 32, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9629837), ('recall', 0.41914633), ('precision', 0.25969023), ('loss', 0.1321716)]))])\n",
            "round 33, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96339744), ('recall', 0.4171951), ('precision', 0.26329055), ('loss', 0.13127962)]))])\n",
            "round 34, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96327364), ('recall', 0.41814023), ('precision', 0.26471722), ('loss', 0.13128738)]))])\n",
            "round 35, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96349746), ('recall', 0.41713414), ('precision', 0.26833764), ('loss', 0.13101836)]))])\n",
            "round 36, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9635449), ('recall', 0.42131096), ('precision', 0.26956537), ('loss', 0.13044895)]))])\n",
            "round 37, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9637775), ('recall', 0.42051828), ('precision', 0.273264), ('loss', 0.12981582)]))])\n",
            "round 38, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9635862), ('recall', 0.41509145), ('precision', 0.27126378), ('loss', 0.13066243)]))])\n",
            "round 39, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96301734), ('recall', 0.38932925), ('precision', 0.26750177), ('loss', 0.13334334)]))])\n",
            "round 40, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9639751), ('recall', 0.42396343), ('precision', 0.27229828), ('loss', 0.129459)]))])\n",
            "round 41, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.964135), ('recall', 0.42076218), ('precision', 0.28255263), ('loss', 0.12864599)]))])\n",
            "round 42, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96416616), ('recall', 0.42640245), ('precision', 0.28196445), ('loss', 0.12860535)]))])\n",
            "round 43, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9644749), ('recall', 0.4275305), ('precision', 0.28410795), ('loss', 0.12781739)]))])\n",
            "round 44, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96401376), ('recall', 0.42573172), ('precision', 0.28026092), ('loss', 0.12901366)]))])\n",
            "round 45, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9644275), ('recall', 0.4332927), ('precision', 0.2868561), ('loss', 0.12751547)]))])\n",
            "round 46, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96448636), ('recall', 0.4345122), ('precision', 0.28878847), ('loss', 0.12714578)]))])\n",
            "round 47, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9643087), ('recall', 0.43310976), ('precision', 0.2828303), ('loss', 0.1276645)]))])\n",
            "round 48, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9645824), ('recall', 0.42823172), ('precision', 0.29203483), ('loss', 0.12699315)]))])\n",
            "round 49, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96493995), ('recall', 0.43756098), ('precision', 0.29411644), ('loss', 0.12572321)]))])\n",
            "round 50, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96491766), ('recall', 0.4322866), ('precision', 0.2971789), ('loss', 0.12575771)]))])\n",
            "round 51, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9651151), ('recall', 0.4350305), ('precision', 0.301002), ('loss', 0.12510854)]))])\n",
            "round 52, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96530133), ('recall', 0.4402744), ('precision', 0.30108), ('loss', 0.12443133)]))])\n",
            "round 53, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96534365), ('recall', 0.4417073), ('precision', 0.3000704), ('loss', 0.124370076)]))])\n",
            "round 54, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96555734), ('recall', 0.44310975), ('precision', 0.30493253), ('loss', 0.123828195)]))])\n",
            "round 55, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9656149), ('recall', 0.44189024), ('precision', 0.30729762), ('loss', 0.12351285)]))])\n",
            "round 56, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9657512), ('recall', 0.44234756), ('precision', 0.30946591), ('loss', 0.122993216)]))])\n",
            "round 57, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96579874), ('recall', 0.4475), ('precision', 0.31193948), ('loss', 0.122764274)]))])\n",
            "round 58, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9657924), ('recall', 0.44710365), ('precision', 0.3144499), ('loss', 0.12230408)]))])\n",
            "round 59, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9657925), ('recall', 0.44884145), ('precision', 0.31108952), ('loss', 0.12261036)]))])\n",
            "round 60, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9659325), ('recall', 0.4484451), ('precision', 0.31321734), ('loss', 0.122038126)]))])\n",
            "round 61, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9661162), ('recall', 0.45359758), ('precision', 0.31420004), ('loss', 0.12137625)]))])\n",
            "round 62, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96609724), ('recall', 0.45597562), ('precision', 0.31538105), ('loss', 0.1212794)]))])\n",
            "round 63, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9664325), ('recall', 0.46246952), ('precision', 0.32095551), ('loss', 0.120107345)]))])\n",
            "round 64, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9662963), ('recall', 0.46692073), ('precision', 0.31855148), ('loss', 0.12064935)]))])\n",
            "round 65, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9662636), ('recall', 0.47990853), ('precision', 0.31098863), ('loss', 0.120532)]))])\n",
            "round 66, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9663524), ('recall', 0.49088416), ('precision', 0.31502026), ('loss', 0.11997482)]))])\n",
            "round 67, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.966465), ('recall', 0.5172561), ('precision', 0.31158862), ('loss', 0.11972174)]))])\n",
            "round 68, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96654373), ('recall', 0.52335364), ('precision', 0.31264913), ('loss', 0.11932698)]))])\n",
            "round 69, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9666836), ('recall', 0.5325305), ('precision', 0.31211135), ('loss', 0.118990935)]))])\n",
            "round 70, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.966705), ('recall', 0.5415854), ('precision', 0.30837065), ('loss', 0.11862293)]))])\n",
            "round 71, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96679), ('recall', 0.55832314), ('precision', 0.31229004), ('loss', 0.11812178)]))])\n",
            "round 72, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96684146), ('recall', 0.5617683), ('precision', 0.31276098), ('loss', 0.11832111)]))])\n",
            "round 73, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9667662), ('recall', 0.5662195), ('precision', 0.3131819), ('loss', 0.11795091)]))])\n",
            "round 74, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96692854), ('recall', 0.5719512), ('precision', 0.31381732), ('loss', 0.117595546)]))])\n",
            "round 75, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96713114), ('recall', 0.5725305), ('precision', 0.31382543), ('loss', 0.11716028)]))])\n",
            "round 76, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96709985), ('recall', 0.57810974), ('precision', 0.31371707), ('loss', 0.116811514)]))])\n",
            "round 77, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96707976), ('recall', 0.5739024), ('precision', 0.3151093), ('loss', 0.117206715)]))])\n",
            "round 78, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96713865), ('recall', 0.57442075), ('precision', 0.3137343), ('loss', 0.117174014)]))])\n",
            "round 79, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9670249), ('recall', 0.57625), ('precision', 0.31006595), ('loss', 0.11693729)]))])\n",
            "round 80, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9674826), ('recall', 0.58387196), ('precision', 0.31903976), ('loss', 0.11563616)]))])\n",
            "round 81, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96753114), ('recall', 0.586311), ('precision', 0.31844148), ('loss', 0.11537537)]))])\n",
            "round 82, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9675086), ('recall', 0.5871341), ('precision', 0.31959242), ('loss', 0.115138456)]))])\n",
            "round 83, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9674637), ('recall', 0.59033537), ('precision', 0.32010248), ('loss', 0.11490751)]))])\n",
            "round 84, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96746004), ('recall', 0.593689), ('precision', 0.32185182), ('loss', 0.114658125)]))])\n",
            "round 85, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9674949), ('recall', 0.5914634), ('precision', 0.31917343), ('loss', 0.11513484)]))])\n",
            "round 86, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9675336), ('recall', 0.593689), ('precision', 0.32260898), ('loss', 0.11477948)]))])\n",
            "round 87, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9677312), ('recall', 0.59765244), ('precision', 0.32241777), ('loss', 0.113914296)]))])\n",
            "round 88, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9676724), ('recall', 0.5948171), ('precision', 0.32226628), ('loss', 0.1143835)]))])\n",
            "round 89, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9677163), ('recall', 0.5995427), ('precision', 0.32153368), ('loss', 0.11398964)]))])\n",
            "round 90, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96783745), ('recall', 0.5994207), ('precision', 0.3233664), ('loss', 0.11344559)]))])\n",
            "round 91, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9678749), ('recall', 0.60210365), ('precision', 0.3253167), ('loss', 0.1133156)]))])\n",
            "round 92, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9680025), ('recall', 0.6021646), ('precision', 0.32515144), ('loss', 0.11290118)]))])\n",
            "round 93, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96795744), ('recall', 0.60057926), ('precision', 0.32551184), ('loss', 0.11310032)]))])\n",
            "round 94, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96796995), ('recall', 0.6092378), ('precision', 0.32606143), ('loss', 0.1126044)]))])\n",
            "round 95, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96804255), ('recall', 0.6085976), ('precision', 0.32651258), ('loss', 0.112203546)]))])\n",
            "round 96, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9681976), ('recall', 0.6115854), ('precision', 0.32807797), ('loss', 0.11193238)]))])\n",
            "round 97, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9685287), ('recall', 0.61210364), ('precision', 0.33103597), ('loss', 0.111264706)]))])\n",
            "round 98, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9684274), ('recall', 0.6107622), ('precision', 0.32724035), ('loss', 0.111628704)]))])\n",
            "round 99, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96836114), ('recall', 0.6163415), ('precision', 0.3246507), ('loss', 0.11109061)]))])\n",
            "round 100, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96859497), ('recall', 0.6163415), ('precision', 0.3327901), ('loss', 0.11059711)]))])\n",
            "round 101, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96843386), ('recall', 0.61655486), ('precision', 0.33227083), ('loss', 0.11064555)]))])\n",
            "round 102, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96860623), ('recall', 0.6179573), ('precision', 0.33172944), ('loss', 0.11065148)]))])\n",
            "round 103, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96859246), ('recall', 0.6218597), ('precision', 0.3342127), ('loss', 0.110017285)]))])\n",
            "round 104, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9686099), ('recall', 0.6242378), ('precision', 0.32681563), ('loss', 0.11032044)]))])\n",
            "round 105, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96862006), ('recall', 0.6234451), ('precision', 0.3349385), ('loss', 0.10998629)]))])\n",
            "round 106, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9687988), ('recall', 0.62179875), ('precision', 0.3337752), ('loss', 0.10968734)]))])\n",
            "round 107, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96881247), ('recall', 0.6283842), ('precision', 0.33546004), ('loss', 0.109140374)]))])\n",
            "round 108, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96900994), ('recall', 0.62682927), ('precision', 0.33272377), ('loss', 0.10886277)]))])\n",
            "round 109, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96877867), ('recall', 0.62615854), ('precision', 0.33241078), ('loss', 0.10937186)]))])\n",
            "round 110, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9692925), ('recall', 0.6307622), ('precision', 0.34020686), ('loss', 0.10819743)]))])\n",
            "round 111, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96867883), ('recall', 0.6278049), ('precision', 0.3325796), ('loss', 0.10911119)]))])\n",
            "round 112, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96913254), ('recall', 0.6332622), ('precision', 0.3367051), ('loss', 0.10803587)]))])\n",
            "round 113, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96893865), ('recall', 0.63189024), ('precision', 0.3342526), ('loss', 0.10856376)]))])\n",
            "round 114, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9691687), ('recall', 0.6345427), ('precision', 0.33516917), ('loss', 0.10787005)]))])\n",
            "round 115, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9691362), ('recall', 0.6362805), ('precision', 0.34092394), ('loss', 0.107736416)]))])\n",
            "round 116, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96933246), ('recall', 0.6364024), ('precision', 0.34117877), ('loss', 0.107232474)]))])\n",
            "round 117, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9693187), ('recall', 0.6402439), ('precision', 0.33869874), ('loss', 0.107141286)]))])\n",
            "round 118, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96842986), ('recall', 0.6047561), ('precision', 0.3308095), ('loss', 0.11171721)]))])\n",
            "round 119, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96860003), ('recall', 0.6285366), ('precision', 0.32405922), ('loss', 0.10961674)]))])\n",
            "round 120, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9691185), ('recall', 0.6409756), ('precision', 0.3352415), ('loss', 0.10739196)]))])\n",
            "round 121, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9691288), ('recall', 0.64125), ('precision', 0.33560976), ('loss', 0.107383244)]))])\n",
            "round 122, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96926004), ('recall', 0.6420122), ('precision', 0.3368687), ('loss', 0.10690162)]))])\n",
            "round 123, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.969295), ('recall', 0.64314026), ('precision', 0.3438748), ('loss', 0.106624626)]))])\n",
            "round 124, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96967256), ('recall', 0.6450915), ('precision', 0.3440432), ('loss', 0.10557872)]))])\n",
            "round 125, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96867234), ('recall', 0.6290549), ('precision', 0.32323912), ('loss', 0.10946914)]))])\n",
            "round 126, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.969235), ('recall', 0.6468902), ('precision', 0.3362812), ('loss', 0.10664332)]))])\n",
            "round 127, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96954757), ('recall', 0.6500305), ('precision', 0.3384608), ('loss', 0.10535126)]))])\n",
            "round 128, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9693938), ('recall', 0.6501829), ('precision', 0.33795005), ('loss', 0.1059555)]))])\n",
            "round 129, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9693287), ('recall', 0.64667684), ('precision', 0.3398545), ('loss', 0.10592538)]))])\n",
            "round 130, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9696574), ('recall', 0.65137196), ('precision', 0.34049436), ('loss', 0.105427034)]))])\n",
            "round 131, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96981), ('recall', 0.6552744), ('precision', 0.3432016), ('loss', 0.1043787)]))])\n",
            "round 132, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96995616), ('recall', 0.6595427), ('precision', 0.3449909), ('loss', 0.10390622)]))])\n",
            "round 133, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.97011125), ('recall', 0.65579265), ('precision', 0.3459423), ('loss', 0.104033165)]))])\n",
            "round 134, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9699388), ('recall', 0.65442073), ('precision', 0.3484465), ('loss', 0.10386725)]))])\n",
            "round 135, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9697937), ('recall', 0.6559756), ('precision', 0.34714985), ('loss', 0.10435219)]))])\n",
            "round 136, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9698637), ('recall', 0.6564939), ('precision', 0.35435352), ('loss', 0.103812784)]))])\n",
            "round 137, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96976495), ('recall', 0.65743905), ('precision', 0.34207937), ('loss', 0.104286484)]))])\n",
            "round 138, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9697212), ('recall', 0.65411586), ('precision', 0.34169453), ('loss', 0.10482066)]))])\n",
            "round 139, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96998614), ('recall', 0.66292685), ('precision', 0.3476815), ('loss', 0.10363625)]))])\n",
            "round 140, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96994996), ('recall', 0.6621342), ('precision', 0.34767157), ('loss', 0.10344174)]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-43k3etjd8P"
      },
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
        "train_metrics = evaluation(state.model, federated_train_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECb3PNHFjk_k"
      },
      "source": [
        "federated_test_data = make_federated_data(test_set)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GoNPIG8Qj0G8",
        "outputId": "e4a61215-ef9d-46bf-8c60-9eecc864eed3"
      },
      "source": [
        "test_metrics = evaluation(state.model, federated_test_data)\n",
        "str(test_metrics)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"OrderedDict([('binary_accuracy', 0.96930003), ('recall', 0.5345912), ('precision', 0.45405984), ('loss', 0.11594644)])\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezubvjWqluK-"
      },
      "source": [
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "state = iterative_process.initialize()\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics['train'].items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM1FgnQao2-h"
      },
      "source": [
        "!ls {logdir}\n",
        "%tensorboard --logdir {logdir} --port=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbnAIOJWo528"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}