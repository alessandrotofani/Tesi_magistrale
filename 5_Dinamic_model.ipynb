{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Dinamic_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqkFAc4JFIDkyZmoQcf+Ic",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/5_Dinamic_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-7rH_UhAPGR"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwkBbxNMK8Fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2deed0-df12-4824-94d4-9b5ca08cbdfa"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd \r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UBtZ7vSkof3"
      },
      "source": [
        "import sys \r\n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\r\n",
        "import mf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYEwRKTV1NvR"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\r\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouPK38wK1Ytv"
      },
      "source": [
        "# Feature engineering and scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s7dk9_P1QQx"
      },
      "source": [
        "data = mf.feature_engineering(data)\r\n",
        "data = mf.feature_scaling(data)\r\n",
        "data = pd.get_dummies(data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrumdQoJ5QF8"
      },
      "source": [
        "# Fraud distribution analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey3rz3gv5TqD"
      },
      "source": [
        "# data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDuj-i196KBr"
      },
      "source": [
        "initial_splits = 4\r\n",
        "splits = 2 \r\n",
        "tot_splits = 10   \r\n",
        "\r\n",
        "def split_data(data, tot_splits, verbose = False):\r\n",
        "  n_data = {}\r\n",
        "  dati_splitted = []\r\n",
        "  dati_fraud = []\r\n",
        "\r\n",
        "  for i in range(tot_splits):\r\n",
        "    dati_splitted.append(data[(data['TransactionDT']>=(i/tot_splits)) & (data['TransactionDT']<((i + 1)/tot_splits))]) \r\n",
        "    dati_fraud.append(dati_splitted[i][dati_splitted[i]['isFraud'] == 1])\r\n",
        "    if verbose: \r\n",
        "      dati_per_split = dati_splitted[i].count()[0]  \r\n",
        "      fraud_per_split = dati_fraud[i].count()[0]  \r\n",
        "      density = fraud_per_split / dati_per_split\r\n",
        "      n_data[i] = [dati_per_split, fraud_per_split, density.round(3)]\r\n",
        "  if verbose:\r\n",
        "    print(n_data)\r\n",
        "    print(dati_splitted)\r\n",
        "    print(dati_fraud)\r\n",
        "\r\n",
        "  return dati_splitted, dati_fraud\r\n",
        "\r\n",
        "dati_splitted, dati_fraud = split_data(data, tot_splits, verbose = False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuNG4I0T6ouy"
      },
      "source": [
        "# def create_ensemble(model_t):\r\n",
        "  # from sklearn.ensemble import VotingClassifier\r\n",
        "  # estimators = []\r\n",
        "  # weights = []\r\n",
        "  # for model in model_t:\r\n",
        "  #   estimators.append((str(model), model))\r\n",
        "  #   weights.append(1)\r\n",
        "  # ensemble = VotingClassifier(estimators=estimators, \r\n",
        "  #                             voting='soft', weights=weights)\r\n",
        "\r\n",
        "  # return ensemble"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH3dJ6teGwJ7"
      },
      "source": [
        "def voting(X_val, y_val, model_t):\r\n",
        "  y_pred_t = []\r\n",
        "  for t in model_t:\r\n",
        "    y_pred_t.append(model_t[t].predict_proba(X_val, validate_features = False)[:, 1]) \r\n",
        "  print(y_pred_t)\r\n",
        "  y_pred = np.mean(y_pred_t, axis = 0)\r\n",
        "  print(y_pred)\r\n",
        "  return y_pred"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdy_H64wz6DN"
      },
      "source": [
        "def train_and_test_model(data, model_t, t):\r\n",
        "  import xgboost \r\n",
        "  from xgboost import XGBClassifier\r\n",
        "  from sklearn.metrics import roc_auc_score\r\n",
        "\r\n",
        "  X_train, X_val, y_train, y_val = mf.split(data, test_size = 0.2)\r\n",
        "\r\n",
        "  model_t[t] = XGBClassifier(n_estimators = 100, max_depth = 2, \r\n",
        "                      objective='binary:logistic', learning_rate = 0.5, \r\n",
        "                      tree_method='gpu_hist') #, sample_weight = [1,30] ) \r\n",
        "  model_t[t].fit(X_train.to_numpy(), y_train.to_numpy())\r\n",
        "  \r\n",
        "  score = roc_auc_score(y_val, model_t[t].predict_proba(X_val, validate_features = False)[:, 1])\r\n",
        "  # ensemble = create_ensemble(model_t)\r\n",
        "  # ensemble_score = roc_auc_score(y_val, ensemble.predict_proba(X_val)[:, 1])\r\n",
        "  if t > 0:\r\n",
        "    ensemble_pred = voting(X_val, y_val, model_t)\r\n",
        "    ensemble_score = roc_auc_score(y_val, ensemble_pred)\r\n",
        "\r\n",
        "    if ensemble_score >= score:\r\n",
        "      print('Ensemble returned with score: ',ensemble_score)\r\n",
        "      return ensemble, ensemble_score\r\n",
        "    if ensemble_score < score:\r\n",
        "      print('New model returned with score: ',score)\r\n",
        "      return clf, score\r\n",
        "  else:\r\n",
        "    return model_t[t], score"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "uKiv5crhgqGt",
        "outputId": "f181550d-dc9c-4c7e-9a0e-f9593f75c5a6"
      },
      "source": [
        "def dinamic_model(initial_splits, splits, tot_splits, data, data_fraud):\r\n",
        "  tmax = np.ceil((tot_splits) / splits)\r\n",
        "  data_t = {}\r\n",
        "  data_fraud_t = {}\r\n",
        "  model_t = {}\r\n",
        "  score = {}\r\n",
        "  ensemble_score = {}\r\n",
        "  print(tmax)\r\n",
        "  for t in range(int(tmax - 1)):\r\n",
        "    if t == 0:\r\n",
        "      start = 0\r\n",
        "      end = initial_splits\r\n",
        "    else:\r\n",
        "      start = splits * (t - 1) + initial_splits\r\n",
        "      end = start + splits\r\n",
        "      start_fraud = splits * (t - 2) + initial_splits\r\n",
        "      end_fraud = start + splits\r\n",
        "      data_fraud_t[t] = pd.concat(data_fraud[start_fraud:end_fraud])\r\n",
        "    data_t[t] = pd.concat(dati_splitted[start:end])\r\n",
        "    if t > 0:\r\n",
        "      data_t[t] = pd.concat([data_t[t], data_fraud[t-1]]) #extract_fraud(data, data_t)\r\n",
        "    print(t)\r\n",
        "    model_t[t], score[t] = train_and_test_model(data_t[t], model_t, t)\r\n",
        "  return model_t[t], score[t]\r\n",
        "\r\n",
        "model, score = dinamic_model(initial_splits, splits, tot_splits, data, dati_fraud)\r\n",
        "print('Score: ', score)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.0\n",
            "0\n",
            "1\n",
            "[array([0.27650017, 0.00941945, 0.00298416, ..., 0.00579162, 0.01244962,\n",
            "       0.00380054], dtype=float32), array([0.13242675, 0.01030081, 0.00328611, ..., 0.00679024, 0.01900152,\n",
            "       0.00540904], dtype=float32)]\n",
            "[0.04176122 0.05065004]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f084db0e391e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdinamic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtot_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdati_fraud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f084db0e391e>\u001b[0m in \u001b[0;36mdinamic_model\u001b[0;34m(initial_splits, splits, tot_splits, data, data_fraud)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mdata_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_fraud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#extract_fraud(data, data_t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-81f4bc9d9b69>\u001b[0m in \u001b[0;36mtrain_and_test_model\u001b[0;34m(data, model_t, t)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mensemble_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mensemble_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensemble_score\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    389\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 225\u001b[0;31m                             sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [23791, 2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc7yVfb5n_Tv"
      },
      "source": [
        "# X_train, X_val, y_train, y_val = mf.split(pd.concat(dati_splitted[:initial_splits - 1]), test_size = 0.2)\r\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCm2QyIkfnm5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjAXR7fYfynW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}