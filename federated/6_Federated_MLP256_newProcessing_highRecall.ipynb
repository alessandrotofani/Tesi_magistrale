{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/6_Federated_MLP256_newProcessing_highRecall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XuZ_oMl43ft"
   },
   "source": [
    "Overview: https://www.tensorflow.org/federated\r\n",
    "\r\n",
    "Image classification tutorial: https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOKJPHxH4j9j"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgkJJpzD4gVs",
    "outputId": "c75d9142-06a2-4392-eed0-54701038e272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 194kB 19.6MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 61kB 10.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
      "\u001b[?25h  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 563kB 19.4MB/s \n",
      "\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 320.4MB 49kB/s \n",
      "\u001b[K     |████████████████████████████████| 20.1MB 1.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 460kB 53.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 522kB 18.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 174kB 19.1MB/s \n",
      "\u001b[K     |████████████████████████████████| 153kB 41.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.0MB 56.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 112kB 52.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.1MB 39.5MB/s \n",
      "\u001b[?25h  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet fastai==2.2.5\r\n",
    "!pip install --quiet folium==0.2.1\r\n",
    "!pip install --quiet imgaug==0.2.5\r\n",
    "!pip install --quiet tensorflow==2.3.0\r\n",
    "!pip install --quiet tensorflow_federated==0.17.0\r\n",
    "!pip install --quiet --upgrade nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C6Oguz1e4p29"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\r\n",
    "nest_asyncio.apply()\r\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0u_qzOek4tlY",
    "outputId": "8f03e483-9484-4764-e17e-8205448411ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import collections\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_federated as tff\r\n",
    "import pandas as pd \r\n",
    "import os\r\n",
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a5VvCBjWmrJC"
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\n",
    "import mf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDXvW9iFxqft"
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8nvRkt1yB7_"
   },
   "source": [
    "I dati vengono importati e poi splittati in train e test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nU2jrVgkla8Y"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "67D33H0kldvF"
   },
   "outputs": [],
   "source": [
    "data = mf.new_processing(data)\n",
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0yGwMV9Us42h"
   },
   "outputs": [],
   "source": [
    "col_name = mf.get_col(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XtEnrz70T013",
    "outputId": "659982c4-08e3-49e4-97e9-1e2268f5ba60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate safe/fraud: 0.036\n"
     ]
    }
   ],
   "source": [
    "print('Rate safe/fraud:', (1/mf.ratio(data)).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "InAYt4jcL1-Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl58v1U4XyO5"
   },
   "source": [
    "Smote: https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.SMOTE.html\n",
    "\n",
    "RandomUnderSampler: https://imbalanced-learn.org/stable/generated/imblearn.under_sampling.RandomUnderSampler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y3Jg0KuzJ6qq"
   },
   "outputs": [],
   "source": [
    "def underSampling(data, frac_under=0.1):\n",
    "  from imblearn.under_sampling import RandomUnderSampler \n",
    "  us = RandomUnderSampler(sampling_strategy=frac_under, random_state=42)\n",
    "  y = data['isFraud']\n",
    "  X = data.drop(columns = ['isFraud'])\n",
    "  X_us, y_us = us.fit_resample(X, y)\n",
    "  return X_us, y_us\n",
    "\n",
    "def overSampling(X, y, frac_over=0.3):\n",
    "  from imblearn.over_sampling import SMOTE\n",
    "  sm = SMOTE(sampling_strategy=frac_over, random_state=42)\n",
    "  X_sm, y_sm = sm.fit_resample(X, y)  \n",
    "  return X_sm, y_sm\n",
    "\n",
    "def mergeResult(X, y, col_name):\n",
    "  y_res = np.ndarray(shape=(np.shape(y)[0],1), buffer = y)\n",
    "  data = np.concatenate((X,y_res), axis = 1)\n",
    "  col_name.append('isFraud')\n",
    "  dataset = pd.DataFrame(data=data, columns=col_name)  \n",
    "  return dataset\n",
    "\n",
    "def rate(y):\n",
    "  n_fraud = np.count_nonzero(y == 1)\n",
    "  n_safe = np.shape(y)[0] - n_fraud\n",
    "  return f'Rate safe/fraud: {n_safe/n_fraud}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "v4cddCAqK4pY",
    "outputId": "091f79f5-1cf5-478c-f52c-3c264c2fd677"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Rate safe/fraud: 10.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = underSampling(train_data)\n",
    "rate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LqiPC-MkK_BX",
    "outputId": "da5483b6-c70d-467c-c51f-f6c564f40001"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Rate safe/fraud: 3.3333333333333335'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = overSampling(X, y)\n",
    "rate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CHpsO2hJLFeR"
   },
   "outputs": [],
   "source": [
    "train_data = mergeResult(X, y, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bpOGbYXMAwY",
    "outputId": "31d2671f-854b-4eee-8c02-a766ae1ace43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 214305\n"
     ]
    }
   ],
   "source": [
    "# print('Rate safe/fraud:', (mf.ratio(train_data)).round(3))\n",
    "print('Dataset size:', train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GawBnA83QyYj"
   },
   "outputs": [],
   "source": [
    "del data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AU9MLDmI2b_o",
    "outputId": "846f30fc-58c5-45d4-c6ea-9d09c90743f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214305, 734)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhZXxAzVxt5B"
   },
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyqEukFeyHXA"
   },
   "source": [
    "Il dataset deve essere convertito in un tensore, con componenti (feature_vector, label). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LuQfRXzrqoW2"
   },
   "outputs": [],
   "source": [
    "def to_tensor(data, n_clients = 4):\n",
    "  shuffled = data.sample(frac=1)\n",
    "  result = np.array_split(shuffled, n_clients)  \n",
    "\n",
    "  res = []\n",
    "  label = []\n",
    "\n",
    "  for dataset in result:\n",
    "    label.append(dataset['isFraud'])\n",
    "    res.append(dataset.drop(columns = ['isFraud']))\n",
    "\n",
    "  dataset = {}\n",
    "  for i in range(n_clients):\n",
    "    dataset[i] = tf.data.Dataset.from_tensor_slices((res[i], label[i]))\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LozyQwZOrCub"
   },
   "outputs": [],
   "source": [
    "dataset = to_tensor(train_data)\n",
    "test_set = to_tensor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "U0_iMvxDQs6l"
   },
   "outputs": [],
   "source": [
    "del train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbRUraJkxzmR"
   },
   "source": [
    "# Federated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWq8QN4vyP1t"
   },
   "source": [
    "Si definisce la funzione di preprocessing del dataset, che serve a creare l'OrderedDict, su cui si andranno a creare le batch necessarie per il training del modello. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vHxlJrXRs9qP"
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 4\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 250\n",
    "SHUFFLE_BUFFER = 10\n",
    "PREFETCH_BUFFER = 10\n",
    "\n",
    "def preprocess(dataset):\n",
    "  def batch_format_fn(e1, e2):\n",
    "    return collections.OrderedDict(\n",
    "        x = tf.cast(e1, tf.float32),\n",
    "        y = tf.cast(e2, tf.int32))\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "\n",
    "preprocessed_example_dataset = preprocess(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcIsH9tRyc0p"
   },
   "source": [
    "I dati federati sono una lista di dataset divisi per cliente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6coH5NXYrQ8A",
    "outputId": "f41facec-60ce-417d-af32-86237091a3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 4\n",
      "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 733)), (y, (None,))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
     ]
    }
   ],
   "source": [
    "def make_federated_data(dataset):\n",
    "  federated = []\n",
    "  for i in dataset:\n",
    "    federated.append(preprocess(dataset[i]))\n",
    "  return federated\n",
    "\n",
    "federated_train_data = make_federated_data(dataset)\n",
    "\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "doNQKip2REvH"
   },
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57xoboqEx25g"
   },
   "source": [
    "# Model creation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oACFRKebyl3u"
   },
   "source": [
    "Creazione della rete neurale che sarà trainata. \n",
    "\n",
    "Viene anche definita la model function, in cui si specifica il modello, il tipo di input, la loss e le metriche da utilizzare. \n",
    "\n",
    "Infine si costruisce il processo di averaging, specificando l'optimizer da usare, cioè SGD, e il learning rate del server e del client. \n",
    "\n",
    "BatchNormalization Layer: https://stackoverflow.com/questions/56514398/why-the-tensorflow-federated-performance-is-worse-than-single-keras-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "F4A7FqBv8G7f"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input, BatchNormalization\n",
    "\n",
    "def create_keras_model():\n",
    "  model = Sequential()\n",
    "  model.add(Input(shape=(733,)))   \n",
    "  model.add(Dense(256, activation='relu')) \n",
    "  # model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  return model\n",
    "\n",
    "def model_fn():\n",
    "  soglia = 0.5\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
    "               tf.keras.metrics.Recall(thresholds=soglia),\n",
    "               tf.keras.metrics.Precision(thresholds=soglia)])\n",
    "  \n",
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,  \n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.4), #0.05\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUUQi8kdzB3_"
   },
   "source": [
    "Training del modello. \n",
    "\n",
    "Gpu usage: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=Y04m-jvKRDsJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjLvHl-fA7wW",
    "outputId": "4dac09a5-55b0-4d63-8cbe-51bf7b3ee640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8207105), ('recall', 0.39631584), ('precision', 0.69594395), ('loss', 0.41008556)]))])\n",
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.83812326), ('recall', 0.47190982), ('precision', 0.7313743), ('loss', 0.37681478)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8479492), ('recall', 0.51156205), ('precision', 0.7501268), ('loss', 0.35742888)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8556206), ('recall', 0.5402932), ('precision', 0.7649489), ('loss', 0.34280273)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8614633), ('recall', 0.5629845), ('precision', 0.7751203), ('loss', 0.33097827)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.86623996), ('recall', 0.5814478), ('precision', 0.7829291), ('loss', 0.3210107)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.87015), ('recall', 0.59662926), ('precision', 0.78917485), ('loss', 0.31307814)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.87345994), ('recall', 0.6097988), ('precision', 0.7940306), ('loss', 0.30554098)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8764266), ('recall', 0.62099886), ('precision', 0.7987428), ('loss', 0.29900905)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8791985), ('recall', 0.631099), ('precision', 0.8032045), ('loss', 0.29344708)]))])\n",
      "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8812546), ('recall', 0.6393671), ('precision', 0.8058592), ('loss', 0.2881894)]))])\n",
      "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.88348323), ('recall', 0.64784956), ('precision', 0.8091759), ('loss', 0.28324586)]))])\n",
      "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.88531506), ('recall', 0.65479326), ('precision', 0.8116763), ('loss', 0.27929178)]))])\n",
      "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.88743263), ('recall', 0.66281265), ('precision', 0.81488293), ('loss', 0.27473098)]))])\n",
      "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8889335), ('recall', 0.6679082), ('precision', 0.8173702), ('loss', 0.27099442)]))])\n",
      "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8906891), ('recall', 0.6741907), ('precision', 0.8200181), ('loss', 0.26735812)]))])\n",
      "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8919612), ('recall', 0.67966235), ('precision', 0.8213906), ('loss', 0.2642151)]))])\n",
      "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.89338607), ('recall', 0.6844101), ('precision', 0.8236824), ('loss', 0.26057082)]))])\n",
      "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8947283), ('recall', 0.6892933), ('precision', 0.82563543), ('loss', 0.25797898)]))])\n",
      "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8960225), ('recall', 0.6936953), ('precision', 0.82771856), ('loss', 0.25523257)]))])\n",
      "round 21, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.89696026), ('recall', 0.69752705), ('precision', 0.8287535), ('loss', 0.25241637)]))])\n",
      "round 22, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.89799535), ('recall', 0.7011), ('precision', 0.8303315), ('loss', 0.24979882)]))])\n",
      "round 23, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.8989635), ('recall', 0.7042746), ('precision', 0.83203894), ('loss', 0.24784501)]))])\n",
      "round 24, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.89999086), ('recall', 0.7083652), ('precision', 0.83325285), ('loss', 0.24519342)]))])\n",
      "round 25, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.90083313), ('recall', 0.71088463), ('precision', 0.83475715), ('loss', 0.24319609)]))])\n",
      "round 26, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9019247), ('recall', 0.71473056), ('precision', 0.83641344), ('loss', 0.24089341)]))])\n",
      "round 27, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9024762), ('recall', 0.7175655), ('precision', 0.83654594), ('loss', 0.23927447)]))])\n",
      "round 28, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.90327406), ('recall', 0.7199333), ('precision', 0.8380322), ('loss', 0.23738098)]))])\n",
      "round 29, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.904061), ('recall', 0.72257), ('precision', 0.83926237), ('loss', 0.23544262)]))])\n",
      "round 30, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.9045844), ('recall', 0.7245597), ('precision', 0.8399065), ('loss', 0.23428065)]))])\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 30\n",
    "state = iterative_process.initialize()\n",
    "for round_num in range(1, NUM_ROUNDS + 1):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA4yp86ex9NK"
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ_L_WaVzGX4"
   },
   "source": [
    "Evaluation del modello sui test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "j-43k3etjd8P"
   },
   "outputs": [],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
    "train_metrics = evaluation(state.model, federated_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ECb3PNHFjk_k"
   },
   "outputs": [],
   "source": [
    "federated_test_data = make_federated_data(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GoNPIG8Qj0G8",
    "outputId": "09ae5c13-9518-4cf1-f056-a73b633f02a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"OrderedDict([('binary_accuracy', 0.94589984), ('recall', 0.59683985), ('precision', 0.34625), ('loss', 0.15436925)])\""
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = evaluation(state.model, federated_test_data)\n",
    "str(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2TBCVOYzJal"
   },
   "source": [
    "Board di tensorboad, per visualizzare la loss e le metriche in modo interattivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ezubvjWqluK-"
   },
   "outputs": [],
   "source": [
    "# logdir = \"/tmp/logs/scalars/training/\"\n",
    "# summary_writer = tf.summary.create_file_writer(logdir)\n",
    "# state = iterative_process.initialize()\n",
    "# with summary_writer.as_default():\n",
    "#   for round_num in range(1, NUM_ROUNDS):\n",
    "#     state, metrics = iterative_process.next(state, federated_train_data)\n",
    "#     for name, value in metrics['train'].items():\n",
    "#       tf.summary.scalar(name, value, step=round_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pM1FgnQao2-h"
   },
   "outputs": [],
   "source": [
    "# !ls {logdir}\n",
    "# %tensorboard --logdir {logdir} --port=0"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN7e25sdWfxWarGIuW6zYoM",
   "include_colab_link": true,
   "name": "6_Federated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
