{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Federated.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKowVxhMbX3U1LrxrcDext",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/6_Federated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XuZ_oMl43ft"
      },
      "source": [
        "Overview: https://www.tensorflow.org/federated\r\n",
        "\r\n",
        "Image classification tutorial: https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOKJPHxH4j9j"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgkJJpzD4gVs"
      },
      "source": [
        "!pip install --quiet tensorflow==2.3.0\r\n",
        "!pip install --quiet tensorflow_federated==0.17.0\r\n",
        "!pip install --quiet --upgrade nest_asyncio\r\n",
        "# !pip install -q tfds-nightly"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Oguz1e4p29"
      },
      "source": [
        "import nest_asyncio\r\n",
        "nest_asyncio.apply()\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u_qzOek4tlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4944544d-bb5a-40f5-d811-d09b41463b05"
      },
      "source": [
        "import collections\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_federated as tff\r\n",
        "import pandas as pd \r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5VvCBjWmrJC"
      },
      "source": [
        "import sys \n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\n",
        "import mf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU2jrVgkla8Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67D33H0kldvF"
      },
      "source": [
        "data = mf.feature_engineering(data)\n",
        "# data = mf.feature_scaling(data)\n",
        "data = pd.get_dummies(data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAZYhrbjnYWz"
      },
      "source": [
        "shuffled = data.sample(frac=1)\n",
        "result = np.array_split(shuffled, 5)  \n",
        "# result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zrb09OGpcl-"
      },
      "source": [
        "res = []\n",
        "for dataset in result:\n",
        "  res.append(mf.feature_scaling(dataset))\n",
        "# res"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2qlgv5pH8-4",
        "outputId": "d5907a0a-501c-4e19-f50d-8e96206df76c"
      },
      "source": [
        "features = mf.get_col(res[0])\n",
        "len(features)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4xP38YmAYWJ"
      },
      "source": [
        "Inserire le prossime due celle nella funzione preprocess e vedere se funziona. \n",
        "\n",
        "provare anche a sostituire il tf.cast per avere un array al posto di un tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsINl6B2961G"
      },
      "source": [
        "new_res = []\n",
        "label = []\n",
        "for subset in res:\n",
        "  label.append(subset['isFraud'])\n",
        "  new_res.append(subset.drop(columns = ['isFraud']).to_numpy())\n",
        "# new_res\n",
        "# label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BNAvkKPgaFN"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((new_res[0], label[0]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN-JTr3k8hJf"
      },
      "source": [
        "del res, new_res"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHxlJrXRs9qP",
        "outputId": "0e3d88c8-5c33-40a9-dab3-fe7f343328b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "NUM_CLIENTS = 5\n",
        "NUM_EPOCHS = 2\n",
        "BATCH_SIZE = 100\n",
        "SHUFFLE_BUFFER = 10\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(e1, e2):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x = tf.cast(e1, tf.float32),\n",
        "        y = tf.cast(e2, tf.int32))\n",
        "      #  x=tf.reshape(element, [-1, 1103]),\n",
        "      #  y=tf.reshape(target, [-1, 1]))\n",
        "        # element)\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "preprocessed_example_dataset = preprocess(dataset)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "sample_batch"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('x',\n",
              "              array([[0.20168072, 0.00437422, 0.56248564, ..., 0.        , 0.        ,\n",
              "                      0.        ],\n",
              "                     [0.03759842, 0.00168205, 0.44044608, ..., 0.        , 0.        ,\n",
              "                      0.        ],\n",
              "                     [0.20247507, 0.00096126, 0.5742125 , ..., 0.        , 0.        ,\n",
              "                      0.        ],\n",
              "                     ...,\n",
              "                     [0.6747616 , 0.00168299, 0.79604506, ..., 0.        , 0.        ,\n",
              "                      0.        ],\n",
              "                     [0.29577255, 0.00490808, 0.42504025, ..., 0.        , 0.        ,\n",
              "                      0.        ],\n",
              "                     [0.889358  , 0.00260668, 0.18808922, ..., 0.        , 0.        ,\n",
              "                      0.        ]], dtype=float32)),\n",
              "             ('y',\n",
              "              array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqsXtfIgnO0z",
        "outputId": "67dbce57-5fb4-42ed-c4f0-f663c1accb52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(dataset)\n",
        "      for x in client_ids\n",
        "  ]\n",
        "\n",
        "sample_clients = np.arange(0,3)#emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_train_data = make_federated_data(dataset, sample_clients)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of client datasets: 3\n",
            "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 1103)), (y, (None,))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4A7FqBv8G7f",
        "outputId": "21d8ddc5-7a96-4e7b-d1db-8589fa33e83c"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input\n",
        "\n",
        "def create_keras_model():\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(1103,))) \n",
        "  # model.add(Dense(1024, activation='relu')) \n",
        "  # model.add(Dropout(0.2)) \n",
        "  model.add(Dense(512, activation='relu')) \n",
        "  model.add(Dropout(0.2)) \n",
        "  model.add(Dense(256, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(128, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(24, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(4, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "  \n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.96532565), ('loss', 0.16143432)]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLvHl-fA7wW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}