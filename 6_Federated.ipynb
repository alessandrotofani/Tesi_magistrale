{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Federated.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNA/SD6uIzABXCJpdejQxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/6_Federated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XuZ_oMl43ft"
      },
      "source": [
        "Overview: https://www.tensorflow.org/federated\r\n",
        "\r\n",
        "Image classification tutorial: https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOKJPHxH4j9j"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgkJJpzD4gVs"
      },
      "source": [
        "!pip install --quiet tensorflow==2.3.0\r\n",
        "!pip install --quiet tensorflow_federated==0.17.0\r\n",
        "!pip install --quiet --upgrade nest_asyncio"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Oguz1e4p29"
      },
      "source": [
        "import nest_asyncio\r\n",
        "nest_asyncio.apply()\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u_qzOek4tlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9376cca9-061d-4c91-9be5-02b1b8ecf646"
      },
      "source": [
        "import collections\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_federated as tff\r\n",
        "import pandas as pd \r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5VvCBjWmrJC"
      },
      "source": [
        "import sys \n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\n",
        "import mf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU2jrVgkla8Y"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67D33H0kldvF"
      },
      "source": [
        "data = mf.feature_engineering(data)\n",
        "# data = mf.feature_scaling(data)\n",
        "data = pd.get_dummies(data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAZYhrbjnYWz"
      },
      "source": [
        "shuffled = data.sample(frac=1)\n",
        "result = np.array_split(shuffled, 5)  \n",
        "# result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zrb09OGpcl-"
      },
      "source": [
        "res = []\n",
        "for dataset in result:\n",
        "  res.append(mf.feature_scaling(dataset))\n",
        "# res"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWMLA0WQviHP"
      },
      "source": [
        "# dataset = []\n",
        "# for subset in res:\n",
        "#   target = subset.pop('isFraud')\n",
        "#   # https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor\n",
        "#   dataset.append(tf.data.Dataset.from_tensor_slices((dict(subset), target.values)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2qlgv5pH8-4",
        "outputId": "5fb2fe0d-91fa-4691-a9c9-b151816ddb1d"
      },
      "source": [
        "features = mf.get_col(res[0])\n",
        "len(features)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4xP38YmAYWJ"
      },
      "source": [
        "Inserire le prossime due celle nella funzione preprocess e vedere se funziona. \n",
        "\n",
        "provare anche a sostituire il tf.cast per avere un array al posto di un tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsINl6B2961G"
      },
      "source": [
        "new_res = []\n",
        "label = []\n",
        "for subset in res:\n",
        "  label.append(subset['isFraud'])\n",
        "  new_res.append(subset.drop(columns = ['isFraud']).to_numpy())\n",
        "# new_res\n",
        "# label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkXZNlZ58hUR"
      },
      "source": [
        "dataset = collections.OrderedDict(\n",
        "          x = tf.cast(new_res[0], tf.float32),\n",
        "          y = tf.cast(label[0], tf.int32))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN-JTr3k8hJf"
      },
      "source": [
        "del res"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocBOhJ0HAHO-",
        "outputId": "04e49057-7b7d-441b-cf16-eb152c934356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('x', <tf.Tensor: shape=(118107, 1103), dtype=float32, numpy=\n",
              "              array([[3.7410889e-02, 8.7390415e-04, 1.6480801e-01, ..., 0.0000000e+00,\n",
              "                      0.0000000e+00, 0.0000000e+00],\n",
              "                     [8.7357983e-02, 1.8395510e-03, 8.5594386e-02, ..., 0.0000000e+00,\n",
              "                      0.0000000e+00, 0.0000000e+00],\n",
              "                     [2.1104421e-02, 3.1233230e-03, 4.3113357e-03, ..., 0.0000000e+00,\n",
              "                      0.0000000e+00, 0.0000000e+00],\n",
              "                     ...,\n",
              "                     [7.0288503e-01, 7.5930404e-04, 4.8746839e-01, ..., 0.0000000e+00,\n",
              "                      0.0000000e+00, 0.0000000e+00],\n",
              "                     [4.7186351e-01, 2.6170157e-03, 8.6583120e-01, ..., 0.0000000e+00,\n",
              "                      0.0000000e+00, 0.0000000e+00],\n",
              "                     [4.2797583e-01, 3.7342103e-03, 8.6583120e-01, ..., 0.0000000e+00,\n",
              "                      0.0000000e+00, 0.0000000e+00]], dtype=float32)>),\n",
              "             ('y',\n",
              "              <tf.Tensor: shape=(118107,), dtype=int32, numpy=array([1, 0, 0, ..., 0, 0, 1], dtype=int32)>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vQxgOidHlPv"
      },
      "source": [
        "# # https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168\n",
        "# dataset = (\n",
        "#     tf.data.Dataset.from_tensor_slices(\n",
        "#         (\n",
        "#             tf.cast(res[0][features].values, tf.float32),\n",
        "#             tf.cast(res[0]['isFraud'].values, tf.int32)\n",
        "#         )\n",
        "#     )\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pguHQTERIy67"
      },
      "source": [
        "# dataset_ordered = collections.OrderedDict(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHxlJrXRs9qP"
      },
      "source": [
        "NUM_CLIENTS = 5\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 100\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x = tf.cast(element[features].values, tf.float32),\n",
        "        y = tf.cast(element['isFraud'].values, tf.int32))\n",
        "      #  x=tf.reshape(element, [-1, 1103]),\n",
        "      #  y=tf.reshape(target, [-1, 1]))\n",
        "        # element)\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "preprocessed_example_dataset = preprocess(alt)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "sample_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lInESUEI7zUW"
      },
      "source": [
        "federated_data = []\n",
        "for subset in dataset:\n",
        "  federated_data.append(preprocess(subset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI-zqGUMEA2A"
      },
      "source": [
        "federated_data[0].element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "F4A7FqBv8G7f",
        "outputId": "02be3847-1a5f-476c-8077-ab1aa1372adc"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input\n",
        "\n",
        "def create_keras_model():\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(1103,))) \n",
        "  # model.add(Dense(1024, activation='relu')) \n",
        "  # model.add(Dropout(0.2)) \n",
        "  model.add(Dense(512, activation='relu')) \n",
        "  model.add(Dropout(0.2)) \n",
        "  model.add(Dense(256, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(128, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(24, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(4, activation='relu')) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "  \n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-f7e794f45c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclient_optimizer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterative_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/federated_averaging.py\u001b[0m in \u001b[0;36mbuild_federated_averaging_process\u001b[0;34m(model_fn, client_optimizer_fn, server_optimizer_fn, client_weight_fn, broadcast_process, aggregation_process, model_update_aggregation_factory, use_experimental_simulation_loop)\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0mbroadcast_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbroadcast_process\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0maggregation_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_process\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m       model_update_aggregation_factory=model_update_aggregation_factory)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py\u001b[0m in \u001b[0;36mbuild_model_delta_optimizer_process\u001b[0;34m(model_fn, model_to_client_delta_fn, server_optimizer_fn, broadcast_process, aggregation_process, model_update_aggregation_factory)\u001b[0m\n\u001b[1;32m    652\u001b[0m       \u001b[0mmodel_to_client_delta_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_to_client_delta_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0mbroadcast_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbroadcast_process\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m       aggregation_process=aggregation_process)\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m   return iterative_process.IterativeProcess(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py\u001b[0m in \u001b[0;36m_build_one_round_computation\u001b[0;34m(model_fn, server_optimizer_fn, model_to_client_delta_fn, broadcast_process, aggregation_process)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   dataset_type = computation_types.SequenceType(\n\u001b[0;32m--> 370\u001b[0;31m       dummy_model_for_metadata.input_spec)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcomputations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_computation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_weights_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/core/api/computation_types.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m       raise TypeError(\n\u001b[1;32m    347\u001b[0m           \u001b[0;34mf'Invalid arguments to `{cls.__name__}` constructor:\\n{message}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m       ) from None\n\u001b[0m\u001b[1;32m    349\u001b[0m     hashable_args = _ValueWithHash(normalized_args,\n\u001b[1;32m    350\u001b[0m                                    cls._hash_normalized_args(*normalized_args))\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid arguments to `SequenceType` constructor:\nInvalid arguments to `StructWithPythonType` constructor:\nUnsupported mapping type dict. Use collections.OrderedDict for mappings."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLvHl-fA7wW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}