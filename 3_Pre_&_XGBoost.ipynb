{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Pre_&_XGBoost.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/O6IcoYmGkY61+XmY1gaK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/3_Pre_%26_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwkBbxNMK8Fv",
        "outputId": "ea932d31-61a1-4fd2-f4f4-148776a4a2d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE'):\r\n",
        "    for filename in filenames:\r\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/train_transaction.csv\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/train_identity.csv\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/original_data.csv\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/num_sign_col.txt\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/fitted.csv\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/num_sign_col_mice.txt\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/cat_sign_col.txt\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/corr_data.csv\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/fitted_old/fitted.csv\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/fitted_old/cat_sign_col.txt\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/fitted_old/num_sign_col_mice.txt\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/fitted_old/readme.txt\n",
            "/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/modelli/catboost\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UBtZ7vSkof3"
      },
      "source": [
        "import sys \r\n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\r\n",
        "import mf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snsMJMlJ3Dcu"
      },
      "source": [
        "## 3.0 Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkebeV1E5pX-"
      },
      "source": [
        "Implemento il min max scaling delle features. \r\n",
        "\r\n",
        "Riferimento: https://towardsdatascience.com/data-normalization-with-pandas-and-scikit-learn-7c1cc6ed6475"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiu5JWhDvX3C"
      },
      "source": [
        "if not os.path.isfile('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/corr_data.csv'):\r\n",
        "  correlation_data = min_max_scaling(correlation_data)\r\n",
        "  correlation_data.to_csv(r'./corr_data.csv')\r\n",
        "\r\n",
        "if not os.path.isfile('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv'):\r\n",
        "  correlation_data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/corr_data.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm21M5BTc2-v"
      },
      "source": [
        "Riferimento `save_model` e `load_model`: https://stackoverflow.com/questions/56107259/how-to-save-a-trained-model-by-scikit-learn\r\n",
        "\r\n",
        "Riferimento confusion matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpbwsvUFX0iY"
      },
      "source": [
        "### Dataset merging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-XUASHDX0iY"
      },
      "source": [
        "Funzione che ritorna la lista delle colonne significative. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUhFjfNyHixl"
      },
      "source": [
        "import warnings\r\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) # serve per ignorare i FutureWarning"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_aHaIF0QR8W"
      },
      "source": [
        "Rimpiazzo i missing values in categorical data con unknown. \r\n",
        "\r\n",
        "Unisco i dataset numerici e categorici nel dataframe data. \r\n",
        "\r\n",
        "Riferimento fillna: https://jamesrledoux.com/code/imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CA67WePVnds"
      },
      "source": [
        "if not os.path.isfile('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv'):\r\n",
        "  col_to_drop = col_not_sign(categorical_data, cat_sign_col)\r\n",
        "  categorical_data = categorical_data.drop(col_to_drop, axis=1)\r\n",
        "  categorical_data = categorical_data.fillna('unknown')\r\n",
        "  data = pd.merge(correlation_data, categorical_data, left_on='TransactionID', right_on='TransactionID', how='left')\r\n",
        "  del correlation_data, categorical_data, numerical_data\r\n",
        "  data.to_csv(r'./data.csv')\r\n",
        "\r\n",
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\r\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jacF5JtkXHvp"
      },
      "source": [
        "## 3.2 One hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YusuKvQSS-V"
      },
      "source": [
        "One hot encoding delle features categoriche. Serve per lo smote e easy ensemble. \r\n",
        "\r\n",
        "Bisogna farlo prima dello split del dataset poichè rischio di perdere delle colonne. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDzEOd7O-E03"
      },
      "source": [
        "data = pd.get_dummies(data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouq64I1r5lkR"
      },
      "source": [
        "cols = mf.get_col(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMz_bK6DTJRl"
      },
      "source": [
        "Seleziono i dati appartenenti ai primi 60 giorni. \r\n",
        "\r\n",
        "Se ne seleziono di più, l'easy ensemble non va. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhRSkafFKcEn"
      },
      "source": [
        "data = mf.select_days(data, 60)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8EkabwNTN1C"
      },
      "source": [
        "Splitto il dataset in train, validation e test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cz8y-FhBpi9"
      },
      "source": [
        "X_train, X_val, y_train, y_val = mf.split(data, test_size = 0.2)\r\n",
        "del data\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIX6IijNRgn0"
      },
      "source": [
        "## 3.3 Undersampling: Easy Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjJGUsMyNGuw"
      },
      "source": [
        "L'easy ensemble tramite un metodo unsupervised divide il dataset in diversi dataset undersampled. \r\n",
        "\r\n",
        "Documentazione easy ensemble: http://glemaitre.github.io/imbalanced-learn/generated/imblearn.ensemble.EasyEnsemble.html#imblearn.ensemble.EasyEnsemble\r\n",
        "\r\n",
        "Esempio applicazio ee: http://glemaitre.github.io/imbalanced-learn/auto_examples/ensemble/plot_easy_ensemble.html?highlight=easy%20ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdiM8saOHFOI"
      },
      "source": [
        "X_trainres, y_trainres = mf.easy_ensemble(5, X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV5gGRbjzBiq"
      },
      "source": [
        "X_trainres_df = pd.DataFrame(data = X_trainres[0], columns = cols)\r\n",
        "del X_trainres"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDxZx1ew9n2I"
      },
      "source": [
        "## 3.4 XGBoost\r\n",
        "\r\n",
        "Provo a trainare un random forest con cross validation sui vari dataset splittati attraverso easy ensemble. \r\n",
        "\r\n",
        "ROC curve: https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_roc_curve_visualization_api.html#sphx-glr-auto-examples-miscellaneous-plot-roc-curve-visualization-api-py\r\n",
        "\r\n",
        "XGBoost: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\r\n",
        "\r\n",
        "gpu_hist method: https://xgboost.readthedocs.io/en/latest/parameter.html#additional-parameters-for-hist-and-gpu-hist-tree-method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSMZzaSzDSml"
      },
      "source": [
        "X_val = X_val.values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ohOclWl9naz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "28732cb7-e276-40cf-bd04-80001812bc24"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.metrics import plot_roc_curve\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "clf = XGBClassifier(n_estimators = 10, max_depth = 2, alpha=0.5, objective='binary:logistic', learning_rate = 1, tree_method='gpu_hist') #learning_rate=0.05)\r\n",
        "# clf = XGBClassifier(n_estimators = 4000, max_depth = 20, alpha=0.5, objective='binary:logistic', learning_rate = 1, tree_method='gpu_hist') #learning_rate=0.05)\r\n",
        "# clf = RandomForestClassifier(n_estimators = 4000, max_depth=10, random_state=0, oob_score = True)\r\n",
        "# clf.fit(X_train, y_train)\r\n",
        "clf.fit(X_trainres[0], y_trainres[0])\r\n",
        "plot_roc_curve(clf, X_val, y_val)\r\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b4f385c729ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# clf = RandomForestClassifier(n_estimators = 4000, max_depth=10, random_state=0, oob_score = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# clf.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trainres_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trainres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: [18:36:03] /workspace/src/tree/updater_gpu_hist.cu:1407: Exception in gpu_hist: NCCL failure :unhandled cuda error /workspace/src/tree/../common/device_helpers.cuh(896)\n\nStack trace:\n  [bt] (0) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f82a81e2cb4]\n  [bt] (1) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::tree::GPUHistMakerSpecialised<xgboost::detail::GradientPairInternal<double> >::Update(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, std::vector<xgboost::RegTree*, std::allocator<xgboost::RegTree*> > const&)+0x1270) [0x7f82a841e7f0]\n  [bt] (2) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::BoostNewTrees(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, int, std::vector<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> >, std::allocator<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> > > >*)+0xa81) [0x7f82a8268791]\n  [bt] (3) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::DoBoost(xgboost::DMatrix*, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::ObjFunction*)+0xd65) [0x7f82a8269c95]\n  [bt] (4) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x396) [0x7f82a827c556]\n  [bt] (5) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7f82a81dfaa5]\n  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f82df682dae]\n  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7f82df68271f]\n  [bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2b4) [0x7f82df8965c4]\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVLAZnmzu8IS"
      },
      "source": [
        "AP max = 0.64\r\n",
        "\r\n",
        "AP: https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOkqeK8SfH_L"
      },
      "source": [
        "mf.ap_metric(clf, X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk437X_johTS"
      },
      "source": [
        "feat_imp = pd.Series(clf.get_booster().get_fscore()).sort_values(ascending=False)\r\n",
        "feat_imp[:20].plot(kind='bar', title='Feature Importances')\r\n",
        "plt.ylabel('Feature Importance Score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVRW3sLJCBMg"
      },
      "source": [
        "#### ROC AUC curve\r\n",
        "\r\n",
        "Riferimento: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV2tW6K5_Qjs"
      },
      "source": [
        "mf.roc_auc_subset(XGBClassifier(), X_trainres, y_trainres, X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBg3Qbe-Nocq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80wDOughNoaG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAtRCt_i88Nu"
      },
      "source": [
        "catboost_cols = X_trainres_df.columns[(X_trainres_df.dtypes == int) | (X_trainres_df.dtypes == float)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRJqtY1FHQyh"
      },
      "source": [
        "Riferimento apply: https://stackoverflow.com/questions/17950374/converting-a-column-within-pandas-dataframe-from-int-to-string\r\n",
        "\r\n",
        "Catboost bad object errore: https://github.com/catboost/catboost/issues/482"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cMmmeFO96x5"
      },
      "source": [
        "for col in X_trainres_df:\r\n",
        "  if col in catboost_cols:\r\n",
        "    X_trainres_df[col] = X_trainres_df[col].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}