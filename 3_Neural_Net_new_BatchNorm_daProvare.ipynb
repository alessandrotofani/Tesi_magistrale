{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Neural_Net.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMkhhapT5/5haWPEP0gqWyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/3_Neural_Net_new_BatchNorm_daProvare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-eTUKS6D9Fs"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtV-QCEPDVju",
        "outputId": "3d3e2b6b-8e01-411e-a1c2-5f28b3cb4957"
      },
      "source": [
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSvV9n8XDd1_"
      },
      "source": [
        "import sys \r\n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\r\n",
        "import mf\r\n",
        "import warnings\r\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLwIrSvoSR7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b554bb-9e27-4e93-ef61-f655068fe0f0"
      },
      "source": [
        "!pip install --quiet fastai==2.2.5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 194kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5aTQo_7D3KW"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CA67WePVnds"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\r\n",
        "data = mf.new_processing(data)\r\n",
        "# data = pd.get_dummies(data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouq64I1r5lkR"
      },
      "source": [
        "cols = mf.get_col(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRYQU4obQE8V"
      },
      "source": [
        "from fastai.tabular.all import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruoqZDmGS48a"
      },
      "source": [
        "categorical_col = data.select_dtypes(include=['object']).columns.tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WHzC-MHVTBV"
      },
      "source": [
        "def get_numerical_col(data, categorical_col):\n",
        "  numerical_col = []\n",
        "  for col in data.columns:\n",
        "    if col not in categorical_col and col != 'isFraud':\n",
        "      numerical_col.append(col)\n",
        "  return numerical_col\n",
        "\n",
        "numerical_col = get_numerical_col(data, categorical_col)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IkJQpHuhnXm"
      },
      "source": [
        "Tutorial: https://docs.fast.ai/tutorial.tabular.html\n",
        "\n",
        "Book: https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uss-vsWXQE3E"
      },
      "source": [
        "fasted = TabularPandas(data, procs=[Categorify],\n",
        "                   cat_names = categorical_col,\n",
        "                   cont_names = numerical_col,\n",
        "                   y_names='isFraud')\n",
        "                  #  splits=splits)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-fjffG1UwkY"
      },
      "source": [
        "X_train, y_train = fasted.xs, fasted.ys.values.ravel()\n",
        "# X_test, y_test = fasted.valid.xs, fasted.valid.ys.values.ravel()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAffYKlMcKoQ"
      },
      "source": [
        "# for col in categorical_col:\n",
        "#   print('Feature',col, 'has',X_train[col].max(), 'different categorical values')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da6EBrZcrZpF"
      },
      "source": [
        "categorical_col_toemb = []\n",
        "one_hot_encode = []\n",
        "for col in categorical_col:\n",
        "  if X_train[col].max() > 7:\n",
        "    categorical_col_toemb.append(col)\n",
        "  else:\n",
        "    one_hot_encode.append(col)\n",
        "\n",
        "X_train = pd.get_dummies(X_train, columns=one_hot_encode)\n",
        "cols = mf.get_col(X_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDwfRa1mr7Jy"
      },
      "source": [
        "numerical_col = get_numerical_col(X_train, categorical_col_toemb)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLwNC-RfdpGF"
      },
      "source": [
        "## Train validation test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8EkabwNTN1C"
      },
      "source": [
        "Splitto il dataset in train, validation e test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTS6eJT9AGlU"
      },
      "source": [
        "def overSampling(X, y, frac_over=0.08):\n",
        "  from imblearn.over_sampling import SMOTE\n",
        "  sm = SMOTE(sampling_strategy=frac_over, random_state=42)\n",
        "  X_sm, y_sm = sm.fit_resample(X, y)  \n",
        "  return X_sm, y_sm"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1lw52XFUZBG"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "X_train, y_train = overSampling(X_train, y_train)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqOMoTQ-xkQo"
      },
      "source": [
        "save_id = False \r\n",
        "\r\n",
        "if save_id:\r\n",
        "  train_id = X_train.index.tolist()\r\n",
        "  val_id = X_val.index.tolist()\r\n",
        "  test_id = X_test.index.tolist()\r\n",
        "  mf.save_list('train_id',train_id)\r\n",
        "  mf.save_list('val_id', val_id)\r\n",
        "  mf.save_list('test_id', test_id)\r\n",
        "\r\n",
        "load_id = False \r\n",
        "if load_id:\r\n",
        "  mf.load_list('train_id',train_id)\r\n",
        "  mf.load_list('val_id', val_id)\r\n",
        "  mf.load_list('test_id', test_id)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcNlmAIrLUcB"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HypjIBuVX2UT"
      },
      "source": [
        "Kaggle tutorial https://www.kaggle.com/colinmorris/embedding-layers\n",
        "\n",
        "Implementation: https://www.kaggle.com/blaskowitz100/dnn-keras-and-categorical-feature-embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-19ItfoMTD0L"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "keras.backend.clear_session()\n",
        "# Embedding for categorical features\n",
        "categorical_input = []\n",
        "numerical_input = []\n",
        "embeddings = []\n",
        "embedding_layer_names = []\n",
        "for col in categorical_col_toemb:\n",
        "# for col in categorical_col:\n",
        "    _input = layers.Input(shape=[1], name=col)\n",
        "    _embed = layers.Embedding(fasted[col].max() + 1, 3, name=col+'_emb')(_input)\n",
        "    categorical_input.append(_input)\n",
        "    embeddings.append(_embed)\n",
        "    embedding_layer_names.append(col+'_emb')\n",
        "    \n",
        "# Simple inputs for the numeric features\n",
        "for col in numerical_col:\n",
        "    numeric_input = layers.Input(shape=(1,), name=col)\n",
        "    numerical_input.append(numeric_input)\n",
        "    \n",
        "# Merge the numeric inputs\n",
        "merged_num_inputs = layers.concatenate(numerical_input)\n",
        "\n",
        "# Merge embedding and use a Droput to prevent overfittting\n",
        "merged_inputs = layers.concatenate(embeddings)\n",
        "spatial_dropout = layers.SpatialDropout1D(0.7)(merged_inputs)\n",
        "flat_embed = layers.Flatten()(spatial_dropout)\n",
        "\n",
        "# Merge embedding and numeric features\n",
        "all_features = layers.concatenate([flat_embed, merged_num_inputs])\n",
        "\n",
        "# MLP for classification\n",
        "# x = layers.Dense(512, activation=tf.keras.activations.gelu)(all_features)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(256, activation=tf.keras.activations.gelu)(all_features)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.7)(x)\n",
        "x = layers.Dense(128, activation=tf.keras.activations.gelu)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.7)(x)\n",
        "x = layers.Dense(64, activation=tf.keras.activations.gelu)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(32, activation=tf.keras.activations.gelu)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(16, activation=tf.keras.activations.gelu)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "# x = layers.Dense(8, activation=tf.keras.activations.gelu)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "# x = layers.Dense(4, activation=tf.keras.activations.gelu)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "\n",
        "# Final model\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = models.Model(inputs=categorical_input + numerical_input, outputs=output)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtPJD6YkUKZe"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "# print(model.summary())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJxOM99jPYxe"
      },
      "source": [
        "def get_keras_dataset(X, cols):\n",
        "  df = pd.DataFrame(data=X, columns=cols)\n",
        "  X = {str(col) : np.array(df[col]) for col in df.columns}\n",
        "  return X"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcxHJc6-OD5P",
        "outputId": "358bb22a-42e6-4814-a9cc-85ce9727cd13"
      },
      "source": [
        "history = model.fit(\r\n",
        "    get_keras_dataset(X_train, cols), \r\n",
        "    y_train,\r\n",
        "    epochs=30, \r\n",
        "    batch_size=512, # 2048 1024 512\r\n",
        "    validation_data=(get_keras_dataset(X_val, cols),y_val),\r\n",
        "    verbose=1,\r\n",
        "    shuffle = True , \r\n",
        "    class_weight = {0: 0.5, 1: 7}\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "722/722 [==============================] - 29s 33ms/step - loss: 0.6730 - accuracy: 0.5562 - recall: 0.6619 - precision: 0.1060 - val_loss: 0.4762 - val_accuracy: 0.7761 - val_recall: 0.6735 - val_precision: 0.1987\n",
            "Epoch 2/30\n",
            "722/722 [==============================] - 23s 31ms/step - loss: 0.5469 - accuracy: 0.6854 - recall: 0.7627 - precision: 0.1602 - val_loss: 0.4816 - val_accuracy: 0.7814 - val_recall: 0.7127 - val_precision: 0.2100\n",
            "Epoch 3/30\n",
            "722/722 [==============================] - 23s 32ms/step - loss: 0.5175 - accuracy: 0.7208 - recall: 0.7738 - precision: 0.1788 - val_loss: 0.5585 - val_accuracy: 0.7401 - val_recall: 0.7764 - val_precision: 0.1901\n",
            "Epoch 4/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.5085 - accuracy: 0.7392 - recall: 0.7684 - precision: 0.1911 - val_loss: 0.5498 - val_accuracy: 0.7405 - val_recall: 0.7980 - val_precision: 0.1936\n",
            "Epoch 5/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.5004 - accuracy: 0.7532 - recall: 0.7644 - precision: 0.1987 - val_loss: 0.6122 - val_accuracy: 0.7160 - val_recall: 0.8205 - val_precision: 0.1824\n",
            "Epoch 6/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.4881 - accuracy: 0.7662 - recall: 0.7622 - precision: 0.2079 - val_loss: 0.3917 - val_accuracy: 0.8598 - val_recall: 0.6583 - val_precision: 0.2964\n",
            "Epoch 7/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.4842 - accuracy: 0.7597 - recall: 0.7725 - precision: 0.2050 - val_loss: 0.5466 - val_accuracy: 0.7541 - val_recall: 0.7849 - val_precision: 0.2008\n",
            "Epoch 8/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.4781 - accuracy: 0.7693 - recall: 0.7748 - precision: 0.2113 - val_loss: 0.4380 - val_accuracy: 0.8241 - val_recall: 0.7312 - val_precision: 0.2564\n",
            "Epoch 9/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.4752 - accuracy: 0.7752 - recall: 0.7741 - precision: 0.2161 - val_loss: 0.4808 - val_accuracy: 0.7899 - val_recall: 0.7804 - val_precision: 0.2286\n",
            "Epoch 10/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.4703 - accuracy: 0.7754 - recall: 0.7775 - precision: 0.2169 - val_loss: 0.5549 - val_accuracy: 0.7608 - val_recall: 0.8160 - val_precision: 0.2102\n",
            "Epoch 11/30\n",
            "722/722 [==============================] - 22s 30ms/step - loss: 0.4632 - accuracy: 0.7794 - recall: 0.7835 - precision: 0.2214 - val_loss: 0.5254 - val_accuracy: 0.7761 - val_recall: 0.8065 - val_precision: 0.2207\n",
            "Epoch 12/30\n",
            "722/722 [==============================] - 22s 31ms/step - loss: 0.4579 - accuracy: 0.7860 - recall: 0.7804 - precision: 0.2268 - val_loss: 0.4229 - val_accuracy: 0.8360 - val_recall: 0.7475 - val_precision: 0.2745\n",
            "Epoch 13/30\n",
            "411/722 [================>.............] - ETA: 7s - loss: 0.4608 - accuracy: 0.7882 - recall: 0.7802 - precision: 0.2295"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-TwZZx0AOxO"
      },
      "source": [
        "# Performance evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKOHvmiVOsaP"
      },
      "source": [
        "# test_loss, test_acc = model.evaluate(get_keras_dataset(X_test, cols), y_test)\r\n",
        "\r\n",
        "# print()\r\n",
        "# print('Test Loss:\\t', test_loss)\r\n",
        "# print('Test Accuracy:\\t', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujQ7C2bhQXLN"
      },
      "source": [
        "y_pred = model.predict(get_keras_dataset(X_test, cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWs-nW4IPaQC"
      },
      "source": [
        "mf.plot_cm(y_test, y_pred, 'Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ivKw-JpPkVG"
      },
      "source": [
        "mf.plot_roc(\"ROC curve\", y_test, y_pred,color='blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbjYisJaYevS"
      },
      "source": [
        "mf.plot_ap('Precision-Recall curve', y_test, y_pred, color = 'red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G6888leAwmt"
      },
      "source": [
        "y_predicted = []\r\n",
        "for prob in y_pred:\r\n",
        "  if prob >= 0.5:\r\n",
        "    y_predicted.append(1)\r\n",
        "  else:\r\n",
        "    y_predicted.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O9ms_BTfptM"
      },
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score\r\n",
        "print('F1 score: ',f1_score(y_test, y_predicted, average=\"binary\"))\r\n",
        "print('Recall: ', recall_score(y_test, y_predicted, average='binary'))\r\n",
        "print('Precision: ', precision_score(y_test, y_predicted,  average='binary'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYR5BCcTm108"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}