{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_LIME.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfn4QTT+VNtod9IaemIcme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrotofani/Tesi_magistrale/blob/master/4_LIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DfTHp7s8Ulb"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7feY4Xy8Odtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21544d9c-e06f-41f0-85b3-eb313940b2ac"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd \r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgOp3wuag3E7"
      },
      "source": [
        "import sys \r\n",
        "sys.path.append('/content/drive/MyDrive/Tesi_magistrale/Tesi_magistrale')\r\n",
        "import mf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caGM5pO_dt0Z"
      },
      "source": [
        "# Dataset import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Dzm6O4dvmE"
      },
      "source": [
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "data = pd.read_csv('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/data.csv')\r\n",
        "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\r\n",
        "\r\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\r\n",
        "time = data['TransactionDT'].values.reshape(-1,1)\r\n",
        "data['TransactionDT'] = min_max_scaler.fit_transform(time)\r\n",
        "data.drop(columns=['TransactionID'], inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK50Ino-zEMT"
      },
      "source": [
        "X_train = mf.get_set('train_id', data, 'catboost_new')\r\n",
        "X_val = mf.get_set('val_id', data, 'catboost_new')\r\n",
        "X_test = mf.get_set('test_id', data, 'catboost_new')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIMk5z4wfCLr"
      },
      "source": [
        "# Model import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ_XVFEWfFD2"
      },
      "source": [
        "### Catboost "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWwxiEZY3SZ8"
      },
      "source": [
        "Riferimento: https://stackoverflow.com/questions/30483246/how-to-check-if-a-python-module-has-been-imported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2N5_UsDfHi_"
      },
      "source": [
        "load_catboost = True\r\n",
        "if load_catboost:\r\n",
        "  if 'catboost' not in sys.modules:\r\n",
        "    !pip install catboost \r\n",
        "  from catboost import CatBoostClassifier\r\n",
        "  cat = CatBoostClassifier()\r\n",
        "  cat.load_model('/content/drive/MyDrive/Tesi_magistrale/Dataset/IEEE/Output/modelli/catboost_new')  \r\n",
        "  categorical_col=mf.load_list('cat_sign_col')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c9SvRtMZzE3"
      },
      "source": [
        "# LIME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhX5K73uZ1Ba"
      },
      "source": [
        "**LIME Local interpretable model-agnostic explanations**\r\n",
        "\r\n",
        "1. LIME generates a new dataset consisting of: \r\n",
        "  * permuted samples, drawing from a normal distribution with mean and standard deviation taken from the feature (in case of tabular data);\r\n",
        "  * the corresponding predictions of the black box model;\r\n",
        "2. On this new dataset LIME then trains an interpretable model;\r\n",
        "3. The model is weighted by the proximity of the sampled instances to the instance of interest.\r\n",
        "\r\n",
        "The **recipe for training local surrogate models**:\r\n",
        "1. Select your instance of interest for which you want to have an explanation of its black box prediction.\r\n",
        "2. Perturb your dataset and get the black box predictions for these new points.\r\n",
        "3. Weight the new samples according to their proximity to the instance of interest.\r\n",
        "4. Train a weighted, interpretable model on the dataset with the variations.\r\n",
        "5. Explain the prediction by interpreting the local model.\r\n",
        "\r\n",
        "Tutorial LIME: https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20continuous%20and%20categorical%20features.html\r\n",
        "\r\n",
        "Documentazione LIME: https://lime-ml.readthedocs.io/en/latest/lime.html\r\n",
        "\r\n",
        "Repository github di lime: https://github.com/marcotcr/lime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIQ-A-e0562s"
      },
      "source": [
        "!pip install lime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX8fdkJB8IP1"
      },
      "source": [
        "Riferimento: https://stackoverflow.com/questions/13021654/get-column-index-from-column-name-in-python-pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbaSsIz76MUk"
      },
      "source": [
        "categorical_features = [X_train.columns.get_loc(col) for col in categorical_col if col in X_train]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4bU915QCYiD",
        "outputId": "ca8ce609-ce02-46b5-e624-118264d2a093"
      },
      "source": [
        "categorical_col"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ProductCD',\n",
              " 'card4',\n",
              " 'card6',\n",
              " 'P_emaildomain',\n",
              " 'R_emaildomain',\n",
              " 'M2',\n",
              " 'M3',\n",
              " 'M4',\n",
              " 'M5',\n",
              " 'M6',\n",
              " 'M7',\n",
              " 'M8',\n",
              " 'M9',\n",
              " 'id_12',\n",
              " 'id_15',\n",
              " 'id_16',\n",
              " 'id_23',\n",
              " 'id_27',\n",
              " 'id_28',\n",
              " 'id_29',\n",
              " 'id_30',\n",
              " 'id_31',\n",
              " 'id_33',\n",
              " 'id_34',\n",
              " 'id_35',\n",
              " 'id_36',\n",
              " 'id_37',\n",
              " 'id_38',\n",
              " 'DeviceType',\n",
              " 'DeviceInfo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kusiY3sBDBtA"
      },
      "source": [
        "Riferimento: https://stackoverflow.com/questions/52404971/get-a-list-of-categories-of-categorical-variable-python-pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1uINOYFCchv"
      },
      "source": [
        "categorical_names=[]\r\n",
        "for col in categorical_col:\r\n",
        "  values = X_train[col].unique()\r\n",
        "  for val in values:\r\n",
        "    if val not in categorical_names:\r\n",
        "      categorical_names.append(val)\r\n",
        "\r\n",
        "# categorical_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSWWTw4teW3x"
      },
      "source": [
        "def lime(X_train, X_test, categorical_features, categorical_names, clf, n_features, j):\r\n",
        "  import lime\r\n",
        "  import lime.lime_tabular\r\n",
        "\r\n",
        "  # setup dell'esxplainer\r\n",
        "  explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.values.tolist(),\r\n",
        "                                                      class_names=[0,1],\r\n",
        "                                                      categorical_features=categorical_features,\r\n",
        "                                                      categorical_names=categorical_names,\r\n",
        "                                                      verbose=True, mode='classification',\r\n",
        "                                                      discretize_continuous = True, discretizer='decile')\r\n",
        "  \r\n",
        "  # explanation\r\n",
        "  exp = explainer.explain_instance(X_test.values[j], clf.predict_proba, num_features=n_features)\r\n",
        "  exp.show_in_notebook(show_table=True)\r\n",
        "  return  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLMgJm2cjl7O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d0153431-d42e-4ac6-ffec-c36636394451"
      },
      "source": [
        "lime(X_train, X_test, categorical_features, categorical_names, cat, 10, 0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3426ba633131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-6ac3193c1116>\u001b[0m in \u001b[0;36mlime\u001b[0;34m(X_train, X_test, categorical_features, categorical_names, clf, n_features, j)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                       \u001b[0mcategorical_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                                       discretize_continuous = True, discretizer='decile')\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# explanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/lime_tabular.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Though set has no role to play if training data stats are provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_frequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'W'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHEd94oA53MQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}